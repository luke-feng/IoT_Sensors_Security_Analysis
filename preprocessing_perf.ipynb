{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "import os,sys\n",
    "import tqdm\n",
    "import pickle\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor  \n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_systemcall_name_perf(line):\n",
    "    l = re.split(r' |\\( |\\)', line)\n",
    "    l = list(filter(lambda a: a != '', l))\n",
    "    # print(l)\n",
    "    if len(l) < 6:\n",
    "        return None\n",
    "    timestamp = l[0]\n",
    "    time_cost = l[1]\n",
    "    pid = l[4]\n",
    "    if l[5] == '...':\n",
    "        if timestamp == '0.000':\n",
    "            return None\n",
    "        else:\n",
    "            syscall = l[7].split('(')[0]\n",
    "    else:\n",
    "        syscall = l[5].split('(')[0]\n",
    "    # print(timestamp,time_cost, pid,  syscall)\n",
    "    return [pid, timestamp, syscall, time_cost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'r') as f, open(filename+'.csv', 'w') as outp:\n",
    "    for line in f:\n",
    "        res = get_systemcall_name_perf(line)\n",
    "        if res != None:\n",
    "            [pid, timestamp, syscall, time_cost] = res\n",
    "            outp.write('{},{},{},{}\\n'.format(pid, timestamp, syscall, time_cost))\n",
    "    f.close()\n",
    "    outp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath ='D:/mt_data/pi3/'\n",
    "perfdataPath = rootPath+'new_t1/'\n",
    "files = os.listdir(perfdataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_systemcall_name_perf(line):\n",
    "    l = re.split(r' |\\( |\\)', line)\n",
    "    l = list(filter(lambda a: a != '', l))\n",
    "    # print(l)\n",
    "    if len(l) < 6:\n",
    "        return None\n",
    "    timestamp = l[0]\n",
    "    time_cost = l[1]\n",
    "    pid = l[4]\n",
    "    try:\n",
    "        if l[5] == '...':\n",
    "            if timestamp == '0.000':\n",
    "                return None\n",
    "            else:\n",
    "                syscall = l[7].split('(')[0]\n",
    "        else:\n",
    "            syscall = l[5].split('(')[0]\n",
    "    except:\n",
    "        print(l)\n",
    "        syscall = None\n",
    "    # print(timestamp,time_cost, pid,  syscall)\n",
    "    return [pid, timestamp, syscall, time_cost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_time(df):\n",
    "    index= 0\n",
    "    time = 0\n",
    "    for index,time in enumerate(df['timestamp']):\n",
    "        if time != 0:\n",
    "            break\n",
    "    for j in range(0,index):\n",
    "        df.loc[j, 'timestamp'] = time\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████▋                                               | 660/3600 [15:21<1:04:27,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['336366698.794', '2.446', 'ms', ':', 'es_sensor/24564', '...', '[c']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████▊              | 2705/3600 [1:02:35<21:03,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['458303234.736', '0.115', 'ms', ':', 'es_sensor/30052', '...', '[continu']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 3600/3600 [1:23:11<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "par = tqdm.tqdm(total=len(files), ncols=100)\n",
    "for fi in files:\n",
    "    if 'txt' in fi:\n",
    "        par.update(1)\n",
    "        syscall_trace = []\n",
    "        with open(perfdataPath + fi, 'r') as f:\n",
    "            for line in f:\n",
    "                res = get_systemcall_name_perf(line)\n",
    "                if res != None:\n",
    "                    syscall_trace.append(res)\n",
    "                # else: \n",
    "                #     print(fi)\n",
    "            f.close()\n",
    "        df = pd.DataFrame(syscall_trace)\n",
    "        df.columns=['pid', 'timestamp', 'syscall', 'time_cost']\n",
    "        path = rootPath + 'trace_t1/' + fi\n",
    "        df.to_csv(path, index=None)\n",
    "        # print(fi, set(df['syscall']))\n",
    "par.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = rootPath + 'trace_t1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_by_time(savePath, malware_type, pid, rounds,df,time_window):\n",
    "    start = 0\n",
    "    end = 0\n",
    "    ti =  df['timestamp'].tolist()\n",
    "    start_time = ti[0]\n",
    "    end_time = 0\n",
    "    index = 0\n",
    "    for i in range(0, len(df)):\n",
    "        end = i\n",
    "        end_time=ti[end]\n",
    "        if end_time - start_time >= time_window * 1000:\n",
    "            fileName = '{}{}_{}_{}_{}_{}_{}.csv'.format(savePath,malware_type,pid, rounds, str(index),str(time_window),str(start_time))\n",
    "            d = df[start:end]\n",
    "            d.to_csv(fileName,index=None)\n",
    "            index += 1\n",
    "            start = end\n",
    "            start_time = end_time         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maltype_from_name(filename):\n",
    "    ns = filename.split('_')\n",
    "    malware_type = ''\n",
    "    pid = ''\n",
    "    rounds = ''\n",
    "    if ns[1] != 'v2':\n",
    "        malware_type =  ns[0]\n",
    "        pid=  ns[1]\n",
    "        rounds =  ns[2]\n",
    "    else:\n",
    "        malware_type = ns[0]+ns[1]\n",
    "        id=  ns[2]\n",
    "        rounds =  ns[3]\n",
    "    return malware_type, pid, rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 600/600 [29:14<00:00,  2.92s/it]\n"
     ]
    }
   ],
   "source": [
    "# tws = [10, 15, 16, 17, 20, 25, 30, 35, 40, 50, 60]\n",
    "tws = [60]\n",
    "datafiles = os.listdir(dataPath)\n",
    "newdataPaht= rootPath+'pi4_4G_splited1/'\n",
    "for tw in tws:\n",
    "    ts = newdataPaht+ str(tw) +'/'  \n",
    "    ls = os.listdir(newdataPaht)\n",
    "    if str(tw) not in ls:\n",
    "        os.mkdir(ts)\n",
    "        ts = newdataPaht + str(tw) +'/'  \n",
    "    par = tqdm.tqdm(total = len(datafiles), ncols=100)\n",
    "    for fi in datafiles:\n",
    "        if '.txt' in fi:\n",
    "            par.update(1)\n",
    "            malware_type, pid, rounds = get_maltype_from_name(fi)\n",
    "            df = pd.read_csv(dataPath+fi)\n",
    "            time_window = tw\n",
    "            split_data_by_time(ts, malware_type, pid, rounds,df,time_window)\n",
    "    par.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syscall_dict(ngrams_dict):\n",
    "    syscall_dict = {}\n",
    "    i = 0\n",
    "    for ngram in ngrams_dict:\n",
    "        if len(ngram.split()) == 1:\n",
    "            syscall_dict[ngram] = i\n",
    "            i+=1\n",
    "    return syscall_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorizers(corpus, ngram):\n",
    "    syscall_dict = {}\n",
    "    ngrams_dict = {}\n",
    "    # countvectorizer = CountVectorizer().fit(corpus)\n",
    "    # syscall_dict = countvectorizer.vocabulary_\n",
    "    countvectorizer = CountVectorizer(ngram_range=(1, ngram)).fit(corpus)\n",
    "    print('create count vectorizer finished')\n",
    "    ngrams_dict = countvectorizer.vocabulary_\n",
    "    syscall_dict = get_syscall_dict(ngrams_dict)\n",
    "    tfidfvectorizer = TfidfVectorizer(ngram_range=(1, ngram), vocabulary=ngrams_dict).fit(corpus)\n",
    "    print('create tf-idf vectorizer finished')\n",
    "    hashingvectorizer = HashingVectorizer(n_features=2**5).fit(corpus)  \n",
    "    print('create hashing vectorizer finished')\n",
    "    return syscall_dict, ngrams_dict, countvectorizer, tfidfvectorizer, hashingvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3321"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw = 50\n",
    "# rawdataPath = rootPath+'data_1/'+str(tw)+'/'\n",
    "rawdataPath ='F:/temp/50/'\n",
    "rawFileNames = os.listdir(rawdataPath)\n",
    "len(rawFileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_trace_to_longstr(syscall_trace):\n",
    "        tracestr = ''\n",
    "        for syscall in syscall_trace:\n",
    "            tracestr += syscall + ' '\n",
    "        # print(tracestr)\n",
    "        return tracestr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdatas = dict()\n",
    "for n in range(0,len(rawFileNames),1000):\n",
    "    start = n\n",
    "    if start + 1000 < len(rawFileNames):\n",
    "        end = start + 1000\n",
    "    else:\n",
    "        end = len(rawFileNames)\n",
    "    rawdatas[n] = rawFileNames[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dataframes, corpuses = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_rawdata(corpus_dataframe,corpus, rawdataPath, rawFileNames):    \n",
    "    pool = ThreadPoolExecutor  (max_workers = 16)\n",
    "    def read_file(inputFilePath):\n",
    "        trace = pd.read_csv(inputFilePath)\n",
    "        tr = trace['syscall'].tolist()             \n",
    "        longstr = from_trace_to_longstr(tr)\n",
    "        return (trace,longstr)\n",
    "        # print(inputFilePath)\n",
    "    def asyn_page(filenames):\n",
    "        future_to_url  = dict()\n",
    "        for i, url in enumerate(filenames):\n",
    "            t = pool.submit(read_file, url)\n",
    "            future_to_url[t] = url               \n",
    "        for future in concurrent.futures.as_completed(future_to_url):\n",
    "            url = future_to_url[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "                (trace,longstr) = data\n",
    "                corpus_dataframe.append(trace)\n",
    "                corpus.append(longstr)\n",
    "            except Exception as exc:\n",
    "                print('%r generated an exception: %s' % (filenames, exc))\n",
    "    \n",
    "    par = tqdm.tqdm(total = len(rawFileNames), ncols=100)\n",
    "    # i = 0\n",
    "    start, end = 0,0\n",
    "    for n in range(0,len(rawFileNames),16):\n",
    "        par.update(16)\n",
    "        start = n\n",
    "        if start + 16 < len(rawFileNames):\n",
    "            end = start + 16\n",
    "        else:\n",
    "            end = len(rawFileNames)\n",
    "        filenames = [rawdataPath + rawFileNames[i] for i in range(start, end)]\n",
    "        asyn_page(filenames)\n",
    "    par.close()\n",
    "    pool.shutdown()\n",
    "    print(\"Sub-process(es) done.\")\n",
    "    return corpus_dataframe, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▉                                                           | 32/1000 [00:01<00:52, 18.40it/s]C:\\Python39\\lib\\concurrent\\futures\\thread.py:52: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  result = self.fn(*self.args, **self.kwargs)\n",
      "1008it [03:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-process(es) done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1008it [03:39,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-process(es) done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1008it [04:02,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-process(es) done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [01:07,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-process(es) done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for rfs in rawdatas:\n",
    "    corpus_dataframe, corpus = [],[]\n",
    "    corpus_dataframe, corpus = read_all_rawdata(corpus_dataframe,corpus, rawdataPath, rawdatas[rfs])\n",
    "    corpus_dataframes[rfs] = corpus_dataframe\n",
    "    corpuses[rfs] = corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dataframe, corpus = [],[]\n",
    "for rfs in corpus_dataframes:\n",
    "    corpus_dataframe += corpus_dataframes[rfs]\n",
    "    corpus += corpuses[rfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create count vectorizer finished\n",
      "create tf-idf vectorizer finished\n",
      "create hashing vectorizer finished\n"
     ]
    }
   ],
   "source": [
    "syscall_dict, ngrams_dict, countvectorizer, tfidfvectorizer, hashingvectorizer = create_vectorizers(corpus, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ngrams_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(syscall_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_onehot_encoding(total, index):\n",
    "    onehot = []\n",
    "    for i in range(0, total):\n",
    "        if i == index:\n",
    "            onehot.append(1)\n",
    "        else:\n",
    "            onehot.append(0)\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_unk_to_dict(syscall_dict):\n",
    "    total = len(syscall_dict)\n",
    "    syscall_dict['unk'] = total\n",
    "    syscall_dict_onehot = dict()\n",
    "    for sc in syscall_dict:\n",
    "        syscall_dict_onehot[sc] = create_onehot_encoding(total+1, syscall_dict[sc])\n",
    "    return syscall_dict, syscall_dict_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "syscall_dict, syscall_dict_onehot = add_unk_to_dict(syscall_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_unk(syscall_trace, syscall_dict):\n",
    "    for i, sc in enumerate(syscall_trace):\n",
    "        if sc.lower() not in syscall_dict:\n",
    "            syscall_trace[i] = 'unk'\n",
    "    return syscall_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_features = countvectorizer.transform(corpus)\n",
    "tfidf_features = tfidfvectorizer.transform(corpus)\n",
    "hashing_features = hashingvectorizer.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_onehot_encoding(trace, syscall_dict_onehot):\n",
    "    encoded_trace = []\n",
    "    for syscall in trace:\n",
    "        syscall = syscall.lower()\n",
    "        if syscall.lower() in syscall_dict_onehot:\n",
    "            one_hot = syscall_dict_onehot[syscall]\n",
    "        else:\n",
    "            syscall = 'UNK'\n",
    "            one_hot = syscall_dict_onehot[syscall]\n",
    "        encoded_trace.append(one_hot)\n",
    "    return encoded_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_head(trace, head):\n",
    "    starts, ends,se = [], [], []\n",
    "\n",
    "    for i,s in enumerate(trace):\n",
    "        if s == head:\n",
    "            start=i\n",
    "            starts.append(start)\n",
    "            if len(starts) > 1:\n",
    "                end = starts[-1] \n",
    "                ends.append(end)\n",
    "        if i == len(trace)-1:\n",
    "            end = len(trace)\n",
    "            ends.append(end)\n",
    "    se = [(starts[i], ends[i]) for i in range(0, len(starts))]\n",
    "    return se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance( trace,head,tails):\n",
    "    se = find_all_head(trace, head)\n",
    "    mw = 12\n",
    "    pool = ThreadPoolExecutor  (max_workers = mw)\n",
    "    distances = []\n",
    "    res = dict()\n",
    "    def return_distance(tails, sort):\n",
    "        distance = dict()\n",
    "        for tail in tails:\n",
    "            d = 0\n",
    "            for j,t in enumerate(sort):\n",
    "                if t==tail:\n",
    "                    d += 1/(j)\n",
    "            distance[tail] = d\n",
    "        return distance\n",
    "\n",
    "    def asyn_page(tails, sorts):\n",
    "        future_to_url  = dict()\n",
    "        for i, url in enumerate(sorts):\n",
    "            t = pool.submit(return_distance, tails=tails, sort=url)\n",
    "            future_to_url[t] = url               \n",
    "        for future in concurrent.futures.as_completed(future_to_url):\n",
    "            url = future_to_url[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "                distance = data\n",
    "                distances.append(distance)\n",
    "            except Exception as exc:\n",
    "                print('generated an exception: %s' % (exc))\n",
    "    start, end = 0,0\n",
    "    for n in range(0, len(se), mw):\n",
    "        start = n\n",
    "        if start + mw < len(rawFileNames):\n",
    "            end = start + mw\n",
    "        else:\n",
    "            end = len(rawFileNames)            \n",
    "        sorts = [trace[s:e] for (s, e) in se[start:end]]\n",
    "        asyn_page(tails, sorts)\n",
    "    pool.shutdown()\n",
    "    # print(\"Sub-process(es) done.\")\n",
    "    ds = pd.DataFrame(distances)\n",
    "    for tail in tails:\n",
    "        if tail in ds:\n",
    "            res[(head, tail)] = sum(ds[tail])\n",
    "        else:\n",
    "            res[(head, tail)] = 0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dependency_graph(trace,term_dict):\n",
    "#     dp = []\n",
    "#     for head in term_dict:\n",
    "#         dp_ = []\n",
    "#         for tail in term_dict:\n",
    "#             if head == tail:\n",
    "#                 dp_.append(0)\n",
    "#             else:\n",
    "#                 distance = get_distance(trace,head,tail)\n",
    "#                 dp_.append(distance)\n",
    "#         dp.append(dp_)\n",
    "#     return dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dependency_graph(trace,term_dict):\n",
    "#     dp_keys = []\n",
    "#     dp = dict()\n",
    "#     for head in term_dict:\n",
    "#         for tail in term_dict:\n",
    "#             dp_key = (head,tail)\n",
    "#             dp_keys.append(dp_key)\n",
    "#             dp[dp_key] = 0\n",
    "#     mw = 12\n",
    "#     pool = ThreadPoolExecutor  (max_workers = mw)\n",
    "      \n",
    "#     def asyn_page(trace, cf):\n",
    "#         future_to_url  = dict()\n",
    "#         for i, url in enumerate(cf):\n",
    "#             (head,tail) = url\n",
    "#             if head == tail:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 t = pool.submit(get_distance, trace,head,tail)\n",
    "#             future_to_url[t] = url               \n",
    "#         for future in concurrent.futures.as_completed(future_to_url):\n",
    "#             url = future_to_url[future]\n",
    "#             try:\n",
    "#                 data = future.result()\n",
    "#                 distance = data\n",
    "#                 dp[url] = distance\n",
    "#             except Exception as exc:\n",
    "#                 print('generated an exception: %s' % ( exc))    \n",
    "#     # i = 0\n",
    "#     start, end = 0,0\n",
    "#     for n in range(0,len(dp_keys),mw):\n",
    "#         start = n\n",
    "#         if start + mw < len(dp_keys):\n",
    "#             end = start + mw\n",
    "#         else:\n",
    "#             end = len(dp_keys)\n",
    "#         cf = dp_keys[start: end]\n",
    "#         asyn_page(trace, cf)\n",
    "#     return dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dependency_graph(trace,term_dict):\n",
    "    dp = []\n",
    "    dp_ = {}\n",
    "    for head in term_dict:\n",
    "        tails = list(term_dict.keys())\n",
    "        tails.remove(head)  \n",
    "        p = get_distance(trace,head,tails)\n",
    "        dp_ = {**dp_, **p}\n",
    "    \n",
    "    for head in term_dict:\n",
    "        d_ =  []\n",
    "        for tail in term_dict:\n",
    "            if head == tail:\n",
    "                d_.append(0)\n",
    "            else:\n",
    "                d_.append(dp_[(head, tail)])\n",
    "        dp.append(d_)\n",
    "    return dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_sequence(trace,term_dict):\n",
    "    dict_sequence = []\n",
    "    for syscall in trace:\n",
    "        if syscall in term_dict:\n",
    "            dict_sequence.append(term_dict[syscall])\n",
    "        else:\n",
    "            dict_sequence.append(term_dict['unk'])\n",
    "    return dict_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot_features = []\n",
    "# dependency_graph_features = []\n",
    "# dict_sequence_features = []\n",
    "\n",
    "# par = tqdm.tqdm(total = len(corpus_dataframe), ncols=100)\n",
    "# for trace in corpus_dataframe:\n",
    "#     par.update(1)\n",
    "#     one_hot = []\n",
    "#     dependency_graph = []\n",
    "#     dict_sequence = []\n",
    "#     syscall_trace = replace_with_unk(trace['syscall'].to_list(), syscall_dict)\n",
    "#     syscall_one_hot =  trace_onehot_encoding(syscall_trace, syscall_dict_onehot)\n",
    "#     dependency_graph = get_dependency_graph(syscall_trace,syscall_dict)\n",
    "#     dict_sequence=get_dict_sequence(syscall_trace,syscall_dict)\n",
    "\n",
    "#     one_hot_features.append(syscall_one_hot)\n",
    "#     dependency_graph_features.append(dependency_graph)  \n",
    "#     dict_sequence_features.append(dict_sequence) \n",
    "# par.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_features(corpus_dataframe, syscall_dict, syscall_dict_onehot):\n",
    "    one_hot_features = []\n",
    "    dependency_graph_features = []\n",
    "    dict_sequence_features = []\n",
    "    pool = ThreadPoolExecutor  (max_workers = 16)\n",
    "\n",
    "    def get_features(trace, syscall_dict, syscall_dict_onehot):\n",
    "        syscall_one_hot = []\n",
    "        dependency_graph = []\n",
    "        dict_sequence = []\n",
    "        syscall_trace = replace_with_unk(trace['syscall'].to_list(), syscall_dict)\n",
    "        syscall_one_hot =  trace_onehot_encoding(syscall_trace, syscall_dict_onehot)\n",
    "        dependency_graph = get_dependency_graph(syscall_trace,syscall_dict)\n",
    "        dict_sequence=get_dict_sequence(syscall_trace,syscall_dict)\n",
    "        return (syscall_one_hot, dependency_graph, dict_sequence)\n",
    "\n",
    "    def asyn_page(cf):\n",
    "        future_to_url  = dict()\n",
    "        for i, url in enumerate(cf):\n",
    "            t = pool.submit(get_features, url, syscall_dict, syscall_dict_onehot)\n",
    "            future_to_url[t] = url               \n",
    "        for future in concurrent.futures.as_completed(future_to_url):\n",
    "            url = future_to_url[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "                (syscall_one_hot, dependency_graph, dict_sequence) = data\n",
    "                one_hot_features.append(syscall_one_hot)\n",
    "                dependency_graph_features.append(dependency_graph)\n",
    "                dict_sequence_features.append(dict_sequence)\n",
    "            except Exception as exc:\n",
    "                print('generated an exception: %s' % ( exc))\n",
    "\n",
    "\n",
    "    par = tqdm.tqdm(total = len(corpus_dataframe), ncols=100)\n",
    "    # i = 0\n",
    "    start, end = 0,0\n",
    "    for n in range(0,len(corpus_dataframe),16):\n",
    "        par.update(16)\n",
    "        start = n\n",
    "        if start + 16 < len(corpus_dataframe):\n",
    "            end = start + 16\n",
    "        else:\n",
    "            end = len(corpus_dataframe)\n",
    "        cf = corpus_dataframe[start: end]\n",
    "        asyn_page(cf)\n",
    "    par.close()   \n",
    "    return one_hot_features, dependency_graph_features, dict_sequence_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3328it [1:21:48,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "one_hot_features, dependency_graph_features, dict_sequence_features = get_sequence_features(corpus_dataframe, syscall_dict, syscall_dict_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "maltype = []\n",
    "ids = []\n",
    "for fi in rawFileNames:\n",
    "    fis = fi.split('_')\n",
    "    fn = fis[0]\n",
    "    i = '{}_{}_{}'.format(fis[0], fis[2], fis[3])\n",
    "    maltype.append(fn)\n",
    "    ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "temppath  ='F:/temp/{}'.format(tw)\n",
    "loc=open(temppath+'ids.pk','wb')\n",
    "pickle.dump(ids,loc)\n",
    "loc=open(temppath+'maltype.pk','wb')\n",
    "pickle.dump(maltype,loc)\n",
    "loc=open(temppath+'frequency_features.pk','wb')\n",
    "pickle.dump(frequency_features,loc)\n",
    "loc=open(temppath+'tfidf_features.pk','wb')\n",
    "pickle.dump(tfidf_features,loc)\n",
    "loc=open(temppath+'hashing_features.pk','wb')\n",
    "pickle.dump(hashing_features,loc)\n",
    "loc=open(temppath+'hashing_features.pk','wb')\n",
    "pickle.dump(hashing_features,loc)\n",
    "\n",
    "loc=open(temppath+'corpus_dataframe.pk','wb')\n",
    "pickle.dump(corpus_dataframe,loc)\n",
    "\n",
    "loc=open(temppath+'corpus.pk','wb')\n",
    "pickle.dump(corpus,loc)\n",
    "loc=open(temppath+'dependency_graph_features.pk','wb')\n",
    "pickle.dump(dependency_graph_features,loc)\n",
    "loc=open(temppath+'one_hot_features.pk','wb')\n",
    "pickle.dump(one_hot_features,loc)\n",
    "loc=open(temppath+'dict_sequence_features.pk','wb')\n",
    "pickle.dump(dict_sequence_features,loc)\n",
    "loc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictPath = rootPath +'dicts/pi4_2G/'+str(tw)+'/'\n",
    "loc=open(dictPath+'countvectorizer.pk','wb')\n",
    "pickle.dump(countvectorizer,loc)\n",
    "loc=open(dictPath+'tfidfvectorizer.pk','wb')\n",
    "pickle.dump(tfidfvectorizer,loc)\n",
    "loc=open(dictPath+'hashingvectorizer.pk','wb')\n",
    "pickle.dump(hashingvectorizer,loc)\n",
    "loc=open(dictPath+'syscall_dict.pk','wb')\n",
    "pickle.dump(syscall_dict,loc)\n",
    "loc=open(dictPath+'syscall_dict_onehot.pk','wb')\n",
    "pickle.dump(syscall_dict_onehot,loc)\n",
    "loc=open(dictPath+'ngrams_dict.pk','wb')\n",
    "pickle.dump(ngrams_dict,loc)\n",
    "loc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temppath  ='F:/temp/'\n",
    "dictPath = rootPath +'dicts/'+str(tw)+'/'\n",
    "\n",
    "# loc=open(temppath+'ids.pk','rb')\n",
    "# ids = pickle.load(loc)\n",
    "# loc=open(temppath+'maltype.pk','rb')\n",
    "# maltype = pickle.load(loc)\n",
    "# loc=open(temppath+'frequency_features.pk','rb')\n",
    "# frequency_features = pickle.load(loc)\n",
    "# loc=open(temppath+'tfidf_features.pk','rb')\n",
    "# tfidf_features = pickle.load(loc)\n",
    "# loc=open(temppath+'hashing_features.pk','rb')\n",
    "# hashing_features = pickle.load(loc)\n",
    "\n",
    "# loc=open(temppath+'corpus_dataframe.pk','rb')\n",
    "# corpus_dataframe = pickle.load(loc)\n",
    "# loc=open(temppath+'corpus.pk','rb')\n",
    "# corpus = pickle.load(loc)\n",
    "\n",
    "loc=open(dictPath+'syscall_dict.pk','rb')\n",
    "syscall_dict = pickle.load(loc)\n",
    "\n",
    "loc=open(dictPath+'syscall_dict_onehot.pk','rb')\n",
    "syscall_dict_onehot = pickle.load(loc)\n",
    "\n",
    "loc=open(dictPath+'ngrams_dict.pk','rb')\n",
    "ngrams_dict = pickle.load(loc)\n",
    "\n",
    "\n",
    "loc=open(dictPath+'countvectorizer.pk','rb')\n",
    "countvectorizer = pickle.load(loc)\n",
    "\n",
    "loc=open(dictPath+'hashingvectorizer.pk','rb')\n",
    "hashingvectorizer = pickle.load(loc)\n",
    "\n",
    "loc=open(dictPath+'tfidfvectorizer.pk','rb')\n",
    "tfidfvectorizer = pickle.load(loc)\n",
    "\n",
    "\n",
    "# loc=open(temppath+'dependency_graph_features.pk','rb')\n",
    "# dependency_graph_features = pickle.load(loc)\n",
    "# loc=open(temppath+'one_hot_features.pk','rb')\n",
    "# one_hot_features = pickle.load(loc)\n",
    "# loc=open(temppath+'dict_sequence_features.pk','rb')\n",
    "# dict_sequence_features = pickle.load(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_trace_df = pd.DataFrame([ids, maltype,frequency_features.toarray() ,tfidf_features.toarray(),hashing_features.toarray(), dependency_graph_features, one_hot_features, dict_sequence_features] ).transpose()\n",
    "encoded_trace_df.columns = ['ids', 'maltype',  'system calls frequency' ,'system calls tfidf','system calls hashing', 'system calls dependency graph', 'one hot encoding', 'dict index encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "temppath  ='F:/temp/{}/'.format(tw)\n",
    "encoded_trace_df.to_pickle(temppath+'encoded_bow.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = 50\n",
    "resultsPath = 'D:/git/IoT_Sensors_Security_Analysis/results/pi4_2G/tw_{}_turn_1/'.format(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temppath  ='F:/temp/'\n",
    "# encoded_trace_df = pd.read_pickle(temppath+'encoded_bow.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidfvectorizer1 = TfidfVectorizer(ngram_range=(1, 5),vocabulary=ngrams_dict)\n",
    "# with open('tfidfvectorizer.pk', 'wb') as fin:\n",
    "#     pickle.dump(tfidfvectorizer1, fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['system calls frequency' ,'system calls tfidf','system calls hashing', 'system calls dependency graph', 'one hot encoding', 'dict index encoding' ]\n",
    "malwares=[\"delay\", \"disorder\", \"freeze\", \"hop\", \"mimic\", \"noise\", \"repeat\", \"spoof\"]\n",
    "# features = ['hashing_features' ,'dependency_graph_features', 'one_hot_features']\n",
    "# malwares=[\"delay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = encoded_trace_df[encoded_trace_df.maltype=='normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import OneClassSVM\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_matrix(matrix_list):\n",
    "    new_list = [np.array(i).reshape(-1) for i in matrix_list]\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_onehot(onehot_list, padding):\n",
    "    new_list = []\n",
    "    for onehot in onehot_list:\n",
    "        if len(onehot) > padding:\n",
    "            onehot = np.array(onehot[0:padding])\n",
    "            new_list.append(onehot)\n",
    "        else:\n",
    "            onehot =np.pad(onehot, [(0, padding-len(onehot)), (0, 0)], mode='constant', constant_values=0)\n",
    "            new_list.append(onehot)\n",
    "    new_list = reshape_matrix(new_list)\n",
    "    return new_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_dictencoding(dictencoding_list, padding):\n",
    "    new_list = []\n",
    "    for onehot in dictencoding_list:\n",
    "        if len(onehot) > padding:\n",
    "            onehot = np.array(onehot[0:padding])\n",
    "            new_list.append(onehot)\n",
    "        else:\n",
    "            onehot =np.pad(onehot, [(0, padding-len(onehot))], mode='constant', constant_values=0)\n",
    "            new_list.append(onehot)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(feature, normal):\n",
    "    X = normal[feature].tolist()\n",
    "    y = normal['maltype'].tolist()\n",
    "    # mlb = LabelBinarizer()\n",
    "    \n",
    "    y = np.zeros(len(X))\n",
    "    # h = .02  # step size in the mesh\n",
    "    outliers_fraction = 0.15\n",
    "    nu = 0.05\n",
    "    clfs = []\n",
    "    results = []\n",
    "    preds = []\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "    y_val_2 = [1 if i==0 else -1 for i in y_val]\n",
    "\n",
    "    X_tv = []\n",
    "    pca = PCA(n_components=100)\n",
    "    if feature =='system calls dependency graph':\n",
    "        X_train = reshape_matrix(X_train)\n",
    "        X_val = reshape_matrix(X_val)    \n",
    "        X_tv=[(X_train,X_val)]\n",
    "        features = [feature]\n",
    "    elif feature =='one hot encoding':\n",
    "        X_train_55000 = padding_onehot(X_train, 55000)\n",
    "        X_val_55000 = padding_onehot(X_val, 55000)\n",
    "        X_train_pca = pca.fit_transform(X_train_55000)\n",
    "        X_val_pca = pca.transform(X_val_55000)\n",
    "        X_tv = [(X_train_pca,X_val_pca)]\n",
    "        features = [feature]\n",
    "    elif feature =='dict index encoding':\n",
    "        X_train_55000 = padding_dictencoding(X_train, 55000)\n",
    "        X_val_55000 = padding_dictencoding(X_val, 55000)\n",
    "        X_train_pca = pca.fit_transform(X_train_55000)\n",
    "        X_val_pca = pca.transform(X_val_55000)\n",
    "        X_train_10000 = padding_dictencoding(X_train, 10000)\n",
    "        X_val_10000 = padding_dictencoding(X_val, 10000)\n",
    "        X_tv = [(X_train_pca,X_val_pca),(X_train_10000,X_val_10000)]\n",
    "        features = [feature+'-pca', feature]\n",
    "    elif feature =='system calls hashing':\n",
    "        X_tv=[(X_train,X_val)]\n",
    "        features = [feature]\n",
    "    else:\n",
    "        X_train_pca = pca.fit_transform(X_train)\n",
    "        X_val_pca = pca.transform(X_val)\n",
    "        X_tv = [(X_train_pca,X_val_pca),(X_train,X_val)]\n",
    "        features = [feature+'-pca', feature]\n",
    "\n",
    "    for i,(X_train,X_val)  in enumerate(X_tv):\n",
    "        feature = features[i]\n",
    "        result = []\n",
    "        pred = dict()\n",
    "        classifiers = {\n",
    "                \"Robust covariance\": EllipticEnvelope(contamination=outliers_fraction),\n",
    "                \"One-Class SVM\": OneClassSVM(nu=outliers_fraction, kernel=\"rbf\",gamma=0.1),\n",
    "                \"SGD One-Class SVM\": SGDOneClassSVM(nu=nu, shuffle=True, fit_intercept=True, random_state=42, tol=1e-4),\n",
    "                \"Isolation Forest\": IsolationForest(contamination=outliers_fraction,random_state=42),\n",
    "            }\n",
    "        for name in classifiers:\n",
    "            clf = classifiers[name]\n",
    "            t1 =time.time()\n",
    "            res = dict()\n",
    "            clf.fit(X_train)\n",
    "            t2 =time.time()\n",
    "            y_pred = clf.predict(X_val)\n",
    "            score = metrics.accuracy_score(y_val_2,y_pred)\n",
    "\n",
    "            pred['valid_'+  feature + '_' + name] = y_pred\n",
    "            t = t2 -t1\n",
    "            res['Model'] ='valid_' + feature + '_' + name\n",
    "            res['Accuracy'] = score\n",
    "            res['Training time'] = t\n",
    "            result.append(res)\n",
    "            print('Model: {}, accuracy score: {}, training time is: {} seconds'.format(res['Model'], score, t))\n",
    "        results.append(result)\n",
    "        preds.append(pred)\n",
    "        clfs.append(classifiers)\n",
    "    pca = pca\n",
    "    return clfs, results, preds, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(malware, feature, clfs, pca):\n",
    "    dfs = encoded_trace_df[encoded_trace_df.maltype==malware]\n",
    "    X_test = dfs[feature].tolist()\n",
    "    X_tv = [] \n",
    "    if feature =='system calls dependency graph':\n",
    "        X_test = reshape_matrix(X_test)    \n",
    "        X_tv=[X_test]\n",
    "        features = [feature]\n",
    "    elif feature =='one hot encoding':\n",
    "        X_test_55000 = padding_onehot(X_test, 55000)\n",
    "        X_test_pca = pca.transform(X_test_55000)\n",
    "        X_tv = [X_test_pca]\n",
    "        features = [feature]\n",
    "    elif feature =='dict index encoding':\n",
    "        X_test_55000 = padding_dictencoding(X_test, 55000)       \n",
    "        X_test_pca = pca.transform(X_test_55000)\n",
    "        X_test_10000 = padding_dictencoding(X_test, 10000)       \n",
    "        X_tv = [X_test_pca, X_test_10000]\n",
    "        features = [feature+'-pca', feature]\n",
    "    elif feature =='system calls hashing':\n",
    "        X_tv=[X_test]\n",
    "        features = [feature]\n",
    "    else:\n",
    "\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "        X_tv = [X_test_pca, X_test]\n",
    "        features = [feature+'-pca', feature]\n",
    "\n",
    "    results = []\n",
    "    preds = []\n",
    "    y_test = np.ones(len(X_test))\n",
    "    y_test_2 = [1 if i==0 else -1 for i in y_test]\n",
    "\n",
    "    for i,classifiers in enumerate(clfs):\n",
    "        feature = features[i]\n",
    "        X_test = X_tv[i]\n",
    "        result = []\n",
    "        pred = dict()    \n",
    "        for name in classifiers:\n",
    "            res = dict()\n",
    "            clf = classifiers[name]\n",
    "            t1 =time.time()\n",
    "            if 'anomaly detection' in name:\n",
    "                y_pred = clf.predict(X_test)\n",
    "                t2 =time.time()\n",
    "                score = metrics.accuracy_score(y_test_2,y_pred)\n",
    "            else:\n",
    "                y_pred = clf.predict(X_test)\n",
    "                t2 =time.time()\n",
    "                score = metrics.accuracy_score(y_test,y_pred)\n",
    "            t = t2 -t1\n",
    "            pred[malware +'_' + feature + '_' + name] = y_pred\n",
    "            res['Model'] = malware +'_' + feature + '_' + name\n",
    "            res['Accuracy'] = score\n",
    "            res['Testing time'] = t\n",
    "            result.append(res)\n",
    "            print('Model: {}, accuracy score: {}, testing time is: {} seconds'.format( res['Model'], score, t))\n",
    "        results.append(result)\n",
    "        preds.append(pred)\n",
    "    return results, preds       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: valid_system calls frequency-pca_Robust covariance, accuracy score: 0.828125, training time is: 3.89487361907959 seconds\n",
      "Model: valid_system calls frequency-pca_One-Class SVM, accuracy score: 0.0, training time is: 0.010002374649047852 seconds\n",
      "Model: valid_system calls frequency-pca_SGD One-Class SVM, accuracy score: 0.359375, training time is: 0.002999544143676758 seconds\n",
      "Model: valid_system calls frequency-pca_Isolation Forest, accuracy score: 0.78125, training time is: 0.13303065299987793 seconds\n",
      "Model: valid_system calls frequency_Robust covariance, accuracy score: 0.8671875, training time is: 19.110288619995117 seconds\n",
      "Model: valid_system calls frequency_One-Class SVM, accuracy score: 0.0, training time is: 0.020003795623779297 seconds\n",
      "Model: valid_system calls frequency_SGD One-Class SVM, accuracy score: 1.0, training time is: 0.002000570297241211 seconds\n",
      "Model: valid_system calls frequency_Isolation Forest, accuracy score: 0.8125, training time is: 0.2270512580871582 seconds\n",
      "Model: delay_system calls frequency-pca_Robust covariance, accuracy score: 0.08888888888888889, testing time is: 0.0009992122650146484 seconds\n",
      "Model: delay_system calls frequency-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.0060007572174072266 seconds\n",
      "Model: delay_system calls frequency-pca_SGD One-Class SVM, accuracy score: 0.4074074074074074, testing time is: 0.0 seconds\n",
      "Model: delay_system calls frequency-pca_Isolation Forest, accuracy score: 0.06666666666666667, testing time is: 0.026006221771240234 seconds\n",
      "Model: delay_system calls frequency_Robust covariance, accuracy score: 0.05925925925925926, testing time is: 0.02400493621826172 seconds\n",
      "Model: delay_system calls frequency_One-Class SVM, accuracy score: 0.0, testing time is: 0.010002374649047852 seconds\n",
      "Model: delay_system calls frequency_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0010001659393310547 seconds\n",
      "Model: delay_system calls frequency_Isolation Forest, accuracy score: 0.6296296296296297, testing time is: 0.04000973701477051 seconds\n",
      "Model: disorder_system calls frequency-pca_Robust covariance, accuracy score: 0.019230769230769232, testing time is: 0.0009996891021728516 seconds\n",
      "Model: disorder_system calls frequency-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.0020003318786621094 seconds\n",
      "Model: disorder_system calls frequency-pca_SGD One-Class SVM, accuracy score: 0.4423076923076923, testing time is: 0.0 seconds\n",
      "Model: disorder_system calls frequency-pca_Isolation Forest, accuracy score: 0.019230769230769232, testing time is: 0.023005247116088867 seconds\n",
      "Model: disorder_system calls frequency_Robust covariance, accuracy score: 0.038461538461538464, testing time is: 0.010002613067626953 seconds\n",
      "Model: disorder_system calls frequency_One-Class SVM, accuracy score: 0.0, testing time is: 0.003999948501586914 seconds\n",
      "Model: disorder_system calls frequency_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: disorder_system calls frequency_Isolation Forest, accuracy score: 0.4807692307692308, testing time is: 0.03000664710998535 seconds\n",
      "Model: freeze_system calls frequency-pca_Robust covariance, accuracy score: 0.0330188679245283, testing time is: 0.0019991397857666016 seconds\n",
      "Model: freeze_system calls frequency-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.018004655838012695 seconds\n",
      "Model: freeze_system calls frequency-pca_SGD One-Class SVM, accuracy score: 0.25943396226415094, testing time is: 0.0010001659393310547 seconds\n",
      "Model: freeze_system calls frequency-pca_Isolation Forest, accuracy score: 0.0330188679245283, testing time is: 0.03600907325744629 seconds\n",
      "Model: freeze_system calls frequency_Robust covariance, accuracy score: 0.030660377358490566, testing time is: 0.07301545143127441 seconds\n",
      "Model: freeze_system calls frequency_One-Class SVM, accuracy score: 0.0, testing time is: 0.032007694244384766 seconds\n",
      "Model: freeze_system calls frequency_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0020008087158203125 seconds\n",
      "Model: freeze_system calls frequency_Isolation Forest, accuracy score: 0.589622641509434, testing time is: 0.07301545143127441 seconds\n",
      "Model: hop_system calls frequency-pca_Robust covariance, accuracy score: 0.8587570621468926, testing time is: 0.0029993057250976562 seconds\n",
      "Model: hop_system calls frequency-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.015004873275756836 seconds\n",
      "Model: hop_system calls frequency-pca_SGD One-Class SVM, accuracy score: 0.2514124293785311, testing time is: 0.0 seconds\n",
      "Model: hop_system calls frequency-pca_Isolation Forest, accuracy score: 0.7457627118644068, testing time is: 0.03600740432739258 seconds\n",
      "Model: hop_system calls frequency_Robust covariance, accuracy score: 0.8728813559322034, testing time is: 0.061013221740722656 seconds\n",
      "Model: hop_system calls frequency_One-Class SVM, accuracy score: 0.0, testing time is: 0.027005672454833984 seconds\n",
      "Model: hop_system calls frequency_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.002000093460083008 seconds\n",
      "Model: hop_system calls frequency_Isolation Forest, accuracy score: 0.8333333333333334, testing time is: 0.06401491165161133 seconds\n",
      "Model: mimic_system calls frequency-pca_Robust covariance, accuracy score: 0.775, testing time is: 0.0010006427764892578 seconds\n",
      "Model: mimic_system calls frequency-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.012003183364868164 seconds\n",
      "Model: mimic_system calls frequency-pca_SGD One-Class SVM, accuracy score: 0.42142857142857143, testing time is: 0.0009996891021728516 seconds\n",
      "Model: mimic_system calls frequency-pca_Isolation Forest, accuracy score: 0.6428571428571429, testing time is: 0.03300738334655762 seconds\n",
      "Model: mimic_system calls frequency_Robust covariance, accuracy score: 0.7607142857142857, testing time is: 0.0490107536315918 seconds\n",
      "Model: mimic_system calls frequency_One-Class SVM, accuracy score: 0.0, testing time is: 0.021005868911743164 seconds\n",
      "Model: mimic_system calls frequency_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0009996891021728516 seconds\n",
      "Model: mimic_system calls frequency_Isolation Forest, accuracy score: 0.65, testing time is: 0.05601239204406738 seconds\n",
      "Model: noise_system calls frequency-pca_Robust covariance, accuracy score: 0.8004750593824228, testing time is: 0.002001047134399414 seconds\n",
      "Model: noise_system calls frequency-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.0180051326751709 seconds\n",
      "Model: noise_system calls frequency-pca_SGD One-Class SVM, accuracy score: 0.25415676959619954, testing time is: 0.0010004043579101562 seconds\n",
      "Model: noise_system calls frequency-pca_Isolation Forest, accuracy score: 0.684085510688836, testing time is: 0.03900766372680664 seconds\n",
      "Model: noise_system calls frequency_Robust covariance, accuracy score: 0.8266033254156769, testing time is: 0.07201600074768066 seconds\n",
      "Model: noise_system calls frequency_One-Class SVM, accuracy score: 0.0, testing time is: 0.03200721740722656 seconds\n",
      "Model: noise_system calls frequency_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0010006427764892578 seconds\n",
      "Model: noise_system calls frequency_Isolation Forest, accuracy score: 0.7648456057007126, testing time is: 0.07201623916625977 seconds\n",
      "Model: repeat_system calls frequency-pca_Robust covariance, accuracy score: 0.018779342723004695, testing time is: 0.002000093460083008 seconds\n",
      "Model: repeat_system calls frequency-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.019005537033081055 seconds\n",
      "Model: repeat_system calls frequency-pca_SGD One-Class SVM, accuracy score: 0.34976525821596244, testing time is: 0.0 seconds\n",
      "Model: repeat_system calls frequency-pca_Isolation Forest, accuracy score: 0.02112676056338028, testing time is: 0.03500819206237793 seconds\n",
      "Model: repeat_system calls frequency_Robust covariance, accuracy score: 0.023474178403755867, testing time is: 0.07401609420776367 seconds\n",
      "Model: repeat_system calls frequency_One-Class SVM, accuracy score: 0.0, testing time is: 0.03300809860229492 seconds\n",
      "Model: repeat_system calls frequency_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.001999378204345703 seconds\n",
      "Model: repeat_system calls frequency_Isolation Forest, accuracy score: 0.676056338028169, testing time is: 0.08101940155029297 seconds\n",
      "Model: spoof_system calls frequency-pca_Robust covariance, accuracy score: 0.03367875647668394, testing time is: 0.0019996166229248047 seconds\n",
      "Model: spoof_system calls frequency-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.01700425148010254 seconds\n",
      "Model: spoof_system calls frequency-pca_SGD One-Class SVM, accuracy score: 0.46113989637305697, testing time is: 0.0010004043579101562 seconds\n",
      "Model: spoof_system calls frequency-pca_Isolation Forest, accuracy score: 0.02072538860103627, testing time is: 0.03500795364379883 seconds\n",
      "Model: spoof_system calls frequency_Robust covariance, accuracy score: 0.038860103626943004, testing time is: 0.06601452827453613 seconds\n",
      "Model: spoof_system calls frequency_One-Class SVM, accuracy score: 0.0, testing time is: 0.028006315231323242 seconds\n",
      "Model: spoof_system calls frequency_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0020008087158203125 seconds\n",
      "Model: spoof_system calls frequency_Isolation Forest, accuracy score: 0.5284974093264249, testing time is: 0.06801486015319824 seconds\n",
      "Model: valid_system calls tfidf-pca_Robust covariance, accuracy score: 0.890625, training time is: 2.878645420074463 seconds\n",
      "Model: valid_system calls tfidf-pca_One-Class SVM, accuracy score: 0.8125, training time is: 0.0010006427764892578 seconds\n",
      "Model: valid_system calls tfidf-pca_SGD One-Class SVM, accuracy score: 1.0, training time is: 0.0010001659393310547 seconds\n",
      "Model: valid_system calls tfidf-pca_Isolation Forest, accuracy score: 0.75, training time is: 0.1360311508178711 seconds\n",
      "Model: valid_system calls tfidf_Robust covariance, accuracy score: 0.84375, training time is: 17.044825077056885 seconds\n",
      "Model: valid_system calls tfidf_One-Class SVM, accuracy score: 0.8125, training time is: 0.0029997825622558594 seconds\n",
      "Model: valid_system calls tfidf_SGD One-Class SVM, accuracy score: 1.0, training time is: 0.003000497817993164 seconds\n",
      "Model: valid_system calls tfidf_Isolation Forest, accuracy score: 0.796875, training time is: 0.2270505428314209 seconds\n",
      "Model: delay_system calls tfidf-pca_Robust covariance, accuracy score: 0.08888888888888889, testing time is: 0.0010004043579101562 seconds\n",
      "Model: delay_system calls tfidf-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.0009999275207519531 seconds\n",
      "Model: delay_system calls tfidf-pca_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: delay_system calls tfidf-pca_Isolation Forest, accuracy score: 0.02962962962962963, testing time is: 0.026006460189819336 seconds\n",
      "Model: delay_system calls tfidf_Robust covariance, accuracy score: 0.014814814814814815, testing time is: 0.023005247116088867 seconds\n",
      "Model: delay_system calls tfidf_One-Class SVM, accuracy score: 0.0, testing time is: 0.0010006427764892578 seconds\n",
      "Model: delay_system calls tfidf_SGD One-Class SVM, accuracy score: 0.9481481481481482, testing time is: 0.0 seconds\n",
      "Model: delay_system calls tfidf_Isolation Forest, accuracy score: 0.674074074074074, testing time is: 0.03900885581970215 seconds\n",
      "Model: disorder_system calls tfidf-pca_Robust covariance, accuracy score: 0.038461538461538464, testing time is: 0.0010004043579101562 seconds\n",
      "Model: disorder_system calls tfidf-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.0 seconds\n",
      "Model: disorder_system calls tfidf-pca_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0010004043579101562 seconds\n",
      "Model: disorder_system calls tfidf-pca_Isolation Forest, accuracy score: 0.0, testing time is: 0.023005247116088867 seconds\n",
      "Model: disorder_system calls tfidf_Robust covariance, accuracy score: 0.019230769230769232, testing time is: 0.009001970291137695 seconds\n",
      "Model: disorder_system calls tfidf_One-Class SVM, accuracy score: 0.0, testing time is: 0.0010008811950683594 seconds\n",
      "Model: disorder_system calls tfidf_SGD One-Class SVM, accuracy score: 0.9615384615384616, testing time is: 0.0 seconds\n",
      "Model: disorder_system calls tfidf_Isolation Forest, accuracy score: 0.5384615384615384, testing time is: 0.03000617027282715 seconds\n",
      "Model: freeze_system calls tfidf-pca_Robust covariance, accuracy score: 0.02830188679245283, testing time is: 0.002000570297241211 seconds\n",
      "Model: freeze_system calls tfidf-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.0019998550415039062 seconds\n",
      "Model: freeze_system calls tfidf-pca_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: freeze_system calls tfidf-pca_Isolation Forest, accuracy score: 0.009433962264150943, testing time is: 0.038008928298950195 seconds\n",
      "Model: freeze_system calls tfidf_Robust covariance, accuracy score: 0.02122641509433962, testing time is: 0.07301783561706543 seconds\n",
      "Model: freeze_system calls tfidf_One-Class SVM, accuracy score: 0.0, testing time is: 0.0050008296966552734 seconds\n",
      "Model: freeze_system calls tfidf_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0010004043579101562 seconds\n",
      "Model: freeze_system calls tfidf_Isolation Forest, accuracy score: 0.5707547169811321, testing time is: 0.08301830291748047 seconds\n",
      "Model: hop_system calls tfidf-pca_Robust covariance, accuracy score: 0.8587570621468926, testing time is: 0.002001047134399414 seconds\n",
      "Model: hop_system calls tfidf-pca_One-Class SVM, accuracy score: 0.8615819209039548, testing time is: 0.001999378204345703 seconds\n",
      "Model: hop_system calls tfidf-pca_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: hop_system calls tfidf-pca_Isolation Forest, accuracy score: 0.751412429378531, testing time is: 0.036008596420288086 seconds\n",
      "Model: hop_system calls tfidf_Robust covariance, accuracy score: 0.864406779661017, testing time is: 0.06101417541503906 seconds\n",
      "Model: hop_system calls tfidf_One-Class SVM, accuracy score: 0.8615819209039548, testing time is: 0.005001068115234375 seconds\n",
      "Model: hop_system calls tfidf_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0010006427764892578 seconds\n",
      "Model: hop_system calls tfidf_Isolation Forest, accuracy score: 0.8559322033898306, testing time is: 0.06401419639587402 seconds\n",
      "Model: mimic_system calls tfidf-pca_Robust covariance, accuracy score: 0.8142857142857143, testing time is: 0.0020012855529785156 seconds\n",
      "Model: mimic_system calls tfidf-pca_One-Class SVM, accuracy score: 0.6714285714285714, testing time is: 0.0010001659393310547 seconds\n",
      "Model: mimic_system calls tfidf-pca_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0009999275207519531 seconds\n",
      "Model: mimic_system calls tfidf-pca_Isolation Forest, accuracy score: 0.5892857142857143, testing time is: 0.03300738334655762 seconds\n",
      "Model: mimic_system calls tfidf_Robust covariance, accuracy score: 0.6857142857142857, testing time is: 0.04801058769226074 seconds\n",
      "Model: mimic_system calls tfidf_One-Class SVM, accuracy score: 0.6714285714285714, testing time is: 0.003000974655151367 seconds\n",
      "Model: mimic_system calls tfidf_SGD One-Class SVM, accuracy score: 0.95, testing time is: 0.0 seconds\n",
      "Model: mimic_system calls tfidf_Isolation Forest, accuracy score: 0.6642857142857143, testing time is: 0.057012319564819336 seconds\n",
      "Model: noise_system calls tfidf-pca_Robust covariance, accuracy score: 0.8669833729216152, testing time is: 0.002000570297241211 seconds\n",
      "Model: noise_system calls tfidf-pca_One-Class SVM, accuracy score: 0.850356294536817, testing time is: 0.0010004043579101562 seconds\n",
      "Model: noise_system calls tfidf-pca_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: noise_system calls tfidf-pca_Isolation Forest, accuracy score: 0.7197149643705463, testing time is: 0.038008689880371094 seconds\n",
      "Model: noise_system calls tfidf_Robust covariance, accuracy score: 0.8242280285035629, testing time is: 0.07201600074768066 seconds\n",
      "Model: noise_system calls tfidf_One-Class SVM, accuracy score: 0.850356294536817, testing time is: 0.0050008296966552734 seconds\n",
      "Model: noise_system calls tfidf_SGD One-Class SVM, accuracy score: 0.997624703087886, testing time is: 0.0009999275207519531 seconds\n",
      "Model: noise_system calls tfidf_Isolation Forest, accuracy score: 0.7980997624703088, testing time is: 0.07101702690124512 seconds\n",
      "Model: repeat_system calls tfidf-pca_Robust covariance, accuracy score: 0.023474178403755867, testing time is: 0.002002239227294922 seconds\n",
      "Model: repeat_system calls tfidf-pca_One-Class SVM, accuracy score: 0.004694835680751174, testing time is: 0.002000570297241211 seconds\n",
      "Model: repeat_system calls tfidf-pca_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: repeat_system calls tfidf-pca_Isolation Forest, accuracy score: 0.018779342723004695, testing time is: 0.03500819206237793 seconds\n",
      "Model: repeat_system calls tfidf_Robust covariance, accuracy score: 0.023474178403755867, testing time is: 0.07301712036132812 seconds\n",
      "Model: repeat_system calls tfidf_One-Class SVM, accuracy score: 0.004694835680751174, testing time is: 0.005000591278076172 seconds\n",
      "Model: repeat_system calls tfidf_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0010006427764892578 seconds\n",
      "Model: repeat_system calls tfidf_Isolation Forest, accuracy score: 0.6924882629107981, testing time is: 0.0710153579711914 seconds\n",
      "Model: spoof_system calls tfidf-pca_Robust covariance, accuracy score: 0.02849740932642487, testing time is: 0.002000570297241211 seconds\n",
      "Model: spoof_system calls tfidf-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.0009996891021728516 seconds\n",
      "Model: spoof_system calls tfidf-pca_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: spoof_system calls tfidf-pca_Isolation Forest, accuracy score: 0.0051813471502590676, testing time is: 0.03400778770446777 seconds\n",
      "Model: spoof_system calls tfidf_Robust covariance, accuracy score: 0.007772020725388601, testing time is: 0.06601428985595703 seconds\n",
      "Model: spoof_system calls tfidf_One-Class SVM, accuracy score: 0.0, testing time is: 0.0050013065338134766 seconds\n",
      "Model: spoof_system calls tfidf_SGD One-Class SVM, accuracy score: 0.9818652849740933, testing time is: 0.0010004043579101562 seconds\n",
      "Model: spoof_system calls tfidf_Isolation Forest, accuracy score: 0.5414507772020726, testing time is: 0.06801462173461914 seconds\n",
      "Model: valid_system calls hashing_Robust covariance, accuracy score: 0.84375, training time is: 0.05401206016540527 seconds\n",
      "Model: valid_system calls hashing_One-Class SVM, accuracy score: 0.65625, training time is: 0.0010008811950683594 seconds\n",
      "Model: valid_system calls hashing_SGD One-Class SVM, accuracy score: 1.0, training time is: 0.0009999275207519531 seconds\n",
      "Model: valid_system calls hashing_Isolation Forest, accuracy score: 0.796875, training time is: 0.12102651596069336 seconds\n",
      "Model: delay_system calls hashing_Robust covariance, accuracy score: 0.0, testing time is: 0.0010001659393310547 seconds\n",
      "Model: delay_system calls hashing_One-Class SVM, accuracy score: 0.0, testing time is: 0.0009996891021728516 seconds\n",
      "Model: delay_system calls hashing_SGD One-Class SVM, accuracy score: 0.9777777777777777, testing time is: 0.0 seconds\n",
      "Model: delay_system calls hashing_Isolation Forest, accuracy score: 0.0, testing time is: 0.02400493621826172 seconds\n",
      "Model: disorder_system calls hashing_Robust covariance, accuracy score: 0.0, testing time is: 0.0 seconds\n",
      "Model: disorder_system calls hashing_One-Class SVM, accuracy score: 0.0, testing time is: 0.0009999275207519531 seconds\n",
      "Model: disorder_system calls hashing_SGD One-Class SVM, accuracy score: 0.9615384615384616, testing time is: 0.0 seconds\n",
      "Model: disorder_system calls hashing_Isolation Forest, accuracy score: 0.0, testing time is: 0.022006511688232422 seconds\n",
      "Model: freeze_system calls hashing_Robust covariance, accuracy score: 0.0, testing time is: 0.0009999275207519531 seconds\n",
      "Model: freeze_system calls hashing_One-Class SVM, accuracy score: 0.0, testing time is: 0.0020008087158203125 seconds\n",
      "Model: freeze_system calls hashing_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: freeze_system calls hashing_Isolation Forest, accuracy score: 0.33962264150943394, testing time is: 0.031005859375 seconds\n",
      "Model: hop_system calls hashing_Robust covariance, accuracy score: 0.864406779661017, testing time is: 0.0010004043579101562 seconds\n",
      "Model: hop_system calls hashing_One-Class SVM, accuracy score: 0.7090395480225988, testing time is: 0.0010001659393310547 seconds\n",
      "Model: hop_system calls hashing_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: hop_system calls hashing_Isolation Forest, accuracy score: 0.8615819209039548, testing time is: 0.030005693435668945 seconds\n",
      "Model: mimic_system calls hashing_Robust covariance, accuracy score: 0.6678571428571428, testing time is: 0.0009999275207519531 seconds\n",
      "Model: mimic_system calls hashing_One-Class SVM, accuracy score: 0.5178571428571429, testing time is: 0.00099945068359375 seconds\n",
      "Model: mimic_system calls hashing_SGD One-Class SVM, accuracy score: 0.9678571428571429, testing time is: 0.0 seconds\n",
      "Model: mimic_system calls hashing_Isolation Forest, accuracy score: 0.6535714285714286, testing time is: 0.028006792068481445 seconds\n",
      "Model: noise_system calls hashing_Robust covariance, accuracy score: 0.8479809976247031, testing time is: 0.0009996891021728516 seconds\n",
      "Model: noise_system calls hashing_One-Class SVM, accuracy score: 0.6769596199524941, testing time is: 0.002001523971557617 seconds\n",
      "Model: noise_system calls hashing_SGD One-Class SVM, accuracy score: 0.997624703087886, testing time is: 0.0 seconds\n",
      "Model: noise_system calls hashing_Isolation Forest, accuracy score: 0.836104513064133, testing time is: 0.031006574630737305 seconds\n",
      "Model: repeat_system calls hashing_Robust covariance, accuracy score: 0.004694835680751174, testing time is: 0.0010001659393310547 seconds\n",
      "Model: repeat_system calls hashing_One-Class SVM, accuracy score: 0.004694835680751174, testing time is: 0.002000570297241211 seconds\n",
      "Model: repeat_system calls hashing_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: repeat_system calls hashing_Isolation Forest, accuracy score: 0.4061032863849765, testing time is: 0.03100728988647461 seconds\n",
      "Model: spoof_system calls hashing_Robust covariance, accuracy score: 0.0, testing time is: 0.0 seconds\n",
      "Model: spoof_system calls hashing_One-Class SVM, accuracy score: 0.0, testing time is: 0.0010001659393310547 seconds\n",
      "Model: spoof_system calls hashing_SGD One-Class SVM, accuracy score: 0.9844559585492227, testing time is: 0.0010006427764892578 seconds\n",
      "Model: spoof_system calls hashing_Isolation Forest, accuracy score: 0.27979274611398963, testing time is: 0.03000617027282715 seconds\n",
      "Model: valid_system calls dependency graph_Robust covariance, accuracy score: 0.8515625, training time is: 10.464348316192627 seconds\n",
      "Model: valid_system calls dependency graph_One-Class SVM, accuracy score: 0.0, training time is: 0.010002374649047852 seconds\n",
      "Model: valid_system calls dependency graph_SGD One-Class SVM, accuracy score: 1.0, training time is: 0.001001119613647461 seconds\n",
      "Model: valid_system calls dependency graph_Isolation Forest, accuracy score: 0.828125, training time is: 0.15703558921813965 seconds\n",
      "Model: delay_system calls dependency graph_Robust covariance, accuracy score: 0.08148148148148149, testing time is: 0.00800180435180664 seconds\n",
      "Model: delay_system calls dependency graph_One-Class SVM, accuracy score: 0.0, testing time is: 0.007001638412475586 seconds\n",
      "Model: delay_system calls dependency graph_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0009996891021728516 seconds\n",
      "Model: delay_system calls dependency graph_Isolation Forest, accuracy score: 0.762962962962963, testing time is: 0.03500843048095703 seconds\n",
      "Model: disorder_system calls dependency graph_Robust covariance, accuracy score: 0.019230769230769232, testing time is: 0.003001689910888672 seconds\n",
      "Model: disorder_system calls dependency graph_One-Class SVM, accuracy score: 0.0, testing time is: 0.0030002593994140625 seconds\n",
      "Model: disorder_system calls dependency graph_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0010008811950683594 seconds\n",
      "Model: disorder_system calls dependency graph_Isolation Forest, accuracy score: 0.7115384615384616, testing time is: 0.027005434036254883 seconds\n",
      "Model: freeze_system calls dependency graph_Robust covariance, accuracy score: 0.03537735849056604, testing time is: 0.023005008697509766 seconds\n",
      "Model: freeze_system calls dependency graph_One-Class SVM, accuracy score: 0.0, testing time is: 0.024005413055419922 seconds\n",
      "Model: freeze_system calls dependency graph_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0010004043579101562 seconds\n",
      "Model: freeze_system calls dependency graph_Isolation Forest, accuracy score: 0.5943396226415094, testing time is: 0.05501246452331543 seconds\n",
      "Model: hop_system calls dependency graph_Robust covariance, accuracy score: 0.864406779661017, testing time is: 0.0200045108795166 seconds\n",
      "Model: hop_system calls dependency graph_One-Class SVM, accuracy score: 0.0, testing time is: 0.01900506019592285 seconds\n",
      "Model: hop_system calls dependency graph_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: hop_system calls dependency graph_Isolation Forest, accuracy score: 0.8333333333333334, testing time is: 0.0490107536315918 seconds\n",
      "Model: mimic_system calls dependency graph_Robust covariance, accuracy score: 0.7785714285714286, testing time is: 0.016003847122192383 seconds\n",
      "Model: mimic_system calls dependency graph_One-Class SVM, accuracy score: 0.0, testing time is: 0.015002965927124023 seconds\n",
      "Model: mimic_system calls dependency graph_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: mimic_system calls dependency graph_Isolation Forest, accuracy score: 0.6535714285714286, testing time is: 0.044008493423461914 seconds\n",
      "Model: noise_system calls dependency graph_Robust covariance, accuracy score: 0.7957244655581948, testing time is: 0.023005247116088867 seconds\n",
      "Model: noise_system calls dependency graph_One-Class SVM, accuracy score: 0.0, testing time is: 0.02400517463684082 seconds\n",
      "Model: noise_system calls dependency graph_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0010001659393310547 seconds\n",
      "Model: noise_system calls dependency graph_Isolation Forest, accuracy score: 0.833729216152019, testing time is: 0.05501294136047363 seconds\n",
      "Model: repeat_system calls dependency graph_Robust covariance, accuracy score: 0.028169014084507043, testing time is: 0.02300548553466797 seconds\n",
      "Model: repeat_system calls dependency graph_One-Class SVM, accuracy score: 0.0, testing time is: 0.02400517463684082 seconds\n",
      "Model: repeat_system calls dependency graph_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0010008811950683594 seconds\n",
      "Model: repeat_system calls dependency graph_Isolation Forest, accuracy score: 0.6854460093896714, testing time is: 0.05501198768615723 seconds\n",
      "Model: spoof_system calls dependency graph_Robust covariance, accuracy score: 0.02849740932642487, testing time is: 0.02100396156311035 seconds\n",
      "Model: spoof_system calls dependency graph_One-Class SVM, accuracy score: 0.0, testing time is: 0.022005319595336914 seconds\n",
      "Model: spoof_system calls dependency graph_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: spoof_system calls dependency graph_Isolation Forest, accuracy score: 0.5155440414507773, testing time is: 0.056012630462646484 seconds\n",
      "Model: valid_one hot encoding_Robust covariance, accuracy score: 1.0, training time is: 2.993671417236328 seconds\n",
      "Model: valid_one hot encoding_One-Class SVM, accuracy score: 0.0, training time is: 0.008001089096069336 seconds\n",
      "Model: valid_one hot encoding_SGD One-Class SVM, accuracy score: 1.0, training time is: 0.0009999275207519531 seconds\n",
      "Model: valid_one hot encoding_Isolation Forest, accuracy score: 1.0, training time is: 0.13302946090698242 seconds\n",
      "Model: delay_one hot encoding_Robust covariance, accuracy score: 1.0, testing time is: 0.0010013580322265625 seconds\n",
      "Model: delay_one hot encoding_One-Class SVM, accuracy score: 0.0, testing time is: 0.0060002803802490234 seconds\n",
      "Model: delay_one hot encoding_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0010001659393310547 seconds\n",
      "Model: delay_one hot encoding_Isolation Forest, accuracy score: 1.0, testing time is: 0.0290067195892334 seconds\n",
      "Model: disorder_one hot encoding_Robust covariance, accuracy score: 1.0, testing time is: 0.0010004043579101562 seconds\n",
      "Model: disorder_one hot encoding_One-Class SVM, accuracy score: 0.0, testing time is: 0.0020003318786621094 seconds\n",
      "Model: disorder_one hot encoding_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: disorder_one hot encoding_Isolation Forest, accuracy score: 1.0, testing time is: 0.02300405502319336 seconds\n",
      "Model: freeze_one hot encoding_Robust covariance, accuracy score: 1.0, testing time is: 0.002001047134399414 seconds\n",
      "Model: freeze_one hot encoding_One-Class SVM, accuracy score: 0.0, testing time is: 0.018004179000854492 seconds\n",
      "Model: freeze_one hot encoding_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0009996891021728516 seconds\n",
      "Model: freeze_one hot encoding_Isolation Forest, accuracy score: 1.0, testing time is: 0.040009260177612305 seconds\n",
      "Model: hop_one hot encoding_Robust covariance, accuracy score: 1.0, testing time is: 0.002001047134399414 seconds\n",
      "Model: hop_one hot encoding_One-Class SVM, accuracy score: 0.0, testing time is: 0.02100515365600586 seconds\n",
      "Model: hop_one hot encoding_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0009992122650146484 seconds\n",
      "Model: hop_one hot encoding_Isolation Forest, accuracy score: 1.0, testing time is: 0.03700971603393555 seconds\n",
      "Model: mimic_one hot encoding_Robust covariance, accuracy score: 1.0, testing time is: 0.0020003318786621094 seconds\n",
      "Model: mimic_one hot encoding_One-Class SVM, accuracy score: 0.0, testing time is: 0.01200246810913086 seconds\n",
      "Model: mimic_one hot encoding_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: mimic_one hot encoding_Isolation Forest, accuracy score: 1.0, testing time is: 0.03500723838806152 seconds\n",
      "Model: noise_one hot encoding_Robust covariance, accuracy score: 1.0, testing time is: 0.002000093460083008 seconds\n",
      "Model: noise_one hot encoding_One-Class SVM, accuracy score: 0.0, testing time is: 0.017003536224365234 seconds\n",
      "Model: noise_one hot encoding_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: noise_one hot encoding_Isolation Forest, accuracy score: 1.0, testing time is: 0.041008949279785156 seconds\n",
      "Model: repeat_one hot encoding_Robust covariance, accuracy score: 1.0, testing time is: 0.0030012130737304688 seconds\n",
      "Model: repeat_one hot encoding_One-Class SVM, accuracy score: 0.0, testing time is: 0.019004106521606445 seconds\n",
      "Model: repeat_one hot encoding_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: repeat_one hot encoding_Isolation Forest, accuracy score: 1.0, testing time is: 0.047011375427246094 seconds\n",
      "Model: spoof_one hot encoding_Robust covariance, accuracy score: 1.0, testing time is: 0.0020003318786621094 seconds\n",
      "Model: spoof_one hot encoding_One-Class SVM, accuracy score: 0.0, testing time is: 0.017004728317260742 seconds\n",
      "Model: spoof_one hot encoding_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.0 seconds\n",
      "Model: spoof_one hot encoding_Isolation Forest, accuracy score: 1.0, testing time is: 0.03800773620605469 seconds\n",
      "Model: valid_dict index encoding-pca_Robust covariance, accuracy score: 0.84375, training time is: 2.0876004695892334 seconds\n",
      "Model: valid_dict index encoding-pca_One-Class SVM, accuracy score: 0.0, training time is: 0.009001970291137695 seconds\n",
      "Model: valid_dict index encoding-pca_SGD One-Class SVM, accuracy score: 0.984375, training time is: 0.0020003318786621094 seconds\n",
      "Model: valid_dict index encoding-pca_Isolation Forest, accuracy score: 0.9765625, training time is: 0.13403081893920898 seconds\n",
      "Model: valid_dict index encoding_Robust covariance, accuracy score: 0.765625, training time is: 9906.439049243927 seconds\n",
      "Model: valid_dict index encoding_One-Class SVM, accuracy score: 0.1171875, training time is: 2.3195152282714844 seconds\n",
      "Model: valid_dict index encoding_SGD One-Class SVM, accuracy score: 1.0, training time is: 0.162034273147583 seconds\n",
      "Model: valid_dict index encoding_Isolation Forest, accuracy score: 0.8125, training time is: 11.835654973983765 seconds\n",
      "Model: delay_dict index encoding-pca_Robust covariance, accuracy score: 0.9777777777777777, testing time is: 0.006998777389526367 seconds\n",
      "Model: delay_dict index encoding-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.01000213623046875 seconds\n",
      "Model: delay_dict index encoding-pca_SGD One-Class SVM, accuracy score: 0.9555555555555556, testing time is: 0.00799870491027832 seconds\n",
      "Model: delay_dict index encoding-pca_Isolation Forest, accuracy score: 0.9777777777777777, testing time is: 0.14404082298278809 seconds\n",
      "Model: delay_dict index encoding_Robust covariance, accuracy score: 0.8222222222222222, testing time is: 40.92317843437195 seconds\n",
      "Model: delay_dict index encoding_One-Class SVM, accuracy score: 0.13333333333333333, testing time is: 1.0822393894195557 seconds\n",
      "Model: delay_dict index encoding_SGD One-Class SVM, accuracy score: 0.9925925925925926, testing time is: 0.014992237091064453 seconds\n",
      "Model: delay_dict index encoding_Isolation Forest, accuracy score: 0.8962962962962963, testing time is: 1.846407413482666 seconds\n",
      "Model: disorder_dict index encoding-pca_Robust covariance, accuracy score: 0.9807692307692307, testing time is: 0.0010104179382324219 seconds\n",
      "Model: disorder_dict index encoding-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.003996133804321289 seconds\n",
      "Model: disorder_dict index encoding-pca_SGD One-Class SVM, accuracy score: 0.9807692307692307, testing time is: 0.0009965896606445312 seconds\n",
      "Model: disorder_dict index encoding-pca_Isolation Forest, accuracy score: 0.9807692307692307, testing time is: 0.05102396011352539 seconds\n",
      "Model: disorder_dict index encoding_Robust covariance, accuracy score: 0.8461538461538461, testing time is: 7.900766849517822 seconds\n",
      "Model: disorder_dict index encoding_One-Class SVM, accuracy score: 0.09615384615384616, testing time is: 0.3040733337402344 seconds\n",
      "Model: disorder_dict index encoding_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.005995512008666992 seconds\n",
      "Model: disorder_dict index encoding_Isolation Forest, accuracy score: 0.9230769230769231, testing time is: 0.638139009475708 seconds\n",
      "Model: freeze_dict index encoding-pca_Robust covariance, accuracy score: 0.9976415094339622, testing time is: 0.004998683929443359 seconds\n",
      "Model: freeze_dict index encoding-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.030010461807250977 seconds\n",
      "Model: freeze_dict index encoding-pca_SGD One-Class SVM, accuracy score: 0.9976415094339622, testing time is: 0.0009989738464355469 seconds\n",
      "Model: freeze_dict index encoding-pca_Isolation Forest, accuracy score: 1.0, testing time is: 0.09602212905883789 seconds\n",
      "Model: freeze_dict index encoding_Robust covariance, accuracy score: 0.6957547169811321, testing time is: 99.85840773582458 seconds\n",
      "Model: freeze_dict index encoding_One-Class SVM, accuracy score: 0.12971698113207547, testing time is: 3.596806764602661 seconds\n",
      "Model: freeze_dict index encoding_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.036009788513183594 seconds\n",
      "Model: freeze_dict index encoding_Isolation Forest, accuracy score: 0.8325471698113207, testing time is: 3.354738235473633 seconds\n",
      "Model: hop_dict index encoding-pca_Robust covariance, accuracy score: 0.9096045197740112, testing time is: 0.005005836486816406 seconds\n",
      "Model: hop_dict index encoding-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.030994415283203125 seconds\n",
      "Model: hop_dict index encoding-pca_SGD One-Class SVM, accuracy score: 0.9971751412429378, testing time is: 0.0 seconds\n",
      "Model: hop_dict index encoding-pca_Isolation Forest, accuracy score: 0.9887005649717514, testing time is: 0.09601378440856934 seconds\n",
      "Model: hop_dict index encoding_Robust covariance, accuracy score: 0.768361581920904, testing time is: 70.73587346076965 seconds\n",
      "Model: hop_dict index encoding_One-Class SVM, accuracy score: 0.14689265536723164, testing time is: 3.8308632373809814 seconds\n",
      "Model: hop_dict index encoding_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.05300760269165039 seconds\n",
      "Model: hop_dict index encoding_Isolation Forest, accuracy score: 0.8559322033898306, testing time is: 6.739508628845215 seconds\n",
      "Model: mimic_dict index encoding-pca_Robust covariance, accuracy score: 0.8357142857142857, testing time is: 0.008002996444702148 seconds\n",
      "Model: mimic_dict index encoding-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.02700519561767578 seconds\n",
      "Model: mimic_dict index encoding-pca_SGD One-Class SVM, accuracy score: 0.9214285714285714, testing time is: 0.0060100555419921875 seconds\n",
      "Model: mimic_dict index encoding-pca_Isolation Forest, accuracy score: 0.9214285714285714, testing time is: 0.1850438117980957 seconds\n",
      "Model: mimic_dict index encoding_Robust covariance, accuracy score: 0.7357142857142858, testing time is: 56.92978763580322 seconds\n",
      "Model: mimic_dict index encoding_One-Class SVM, accuracy score: 0.14285714285714285, testing time is: 1.6033501625061035 seconds\n",
      "Model: mimic_dict index encoding_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.026003599166870117 seconds\n",
      "Model: mimic_dict index encoding_Isolation Forest, accuracy score: 0.7357142857142858, testing time is: 2.9576618671417236 seconds\n",
      "Model: noise_dict index encoding-pca_Robust covariance, accuracy score: 0.8693586698337292, testing time is: 0.00400233268737793 seconds\n",
      "Model: noise_dict index encoding-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.05501079559326172 seconds\n",
      "Model: noise_dict index encoding-pca_SGD One-Class SVM, accuracy score: 0.9881235154394299, testing time is: 0.0009975433349609375 seconds\n",
      "Model: noise_dict index encoding-pca_Isolation Forest, accuracy score: 0.9738717339667459, testing time is: 0.11802482604980469 seconds\n",
      "Model: noise_dict index encoding_Robust covariance, accuracy score: 0.7505938242280285, testing time is: 98.50911402702332 seconds\n",
      "Model: noise_dict index encoding_One-Class SVM, accuracy score: 0.17577197149643706, testing time is: 2.678588390350342 seconds\n",
      "Model: noise_dict index encoding_SGD One-Class SVM, accuracy score: 0.997624703087886, testing time is: 0.03700113296508789 seconds\n",
      "Model: noise_dict index encoding_Isolation Forest, accuracy score: 0.8551068883610451, testing time is: 4.254952907562256 seconds\n",
      "Model: repeat_dict index encoding-pca_Robust covariance, accuracy score: 0.9976525821596244, testing time is: 0.0059969425201416016 seconds\n",
      "Model: repeat_dict index encoding-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.04298877716064453 seconds\n",
      "Model: repeat_dict index encoding-pca_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.001001119613647461 seconds\n",
      "Model: repeat_dict index encoding-pca_Isolation Forest, accuracy score: 1.0, testing time is: 0.07301545143127441 seconds\n",
      "Model: repeat_dict index encoding_Robust covariance, accuracy score: 0.744131455399061, testing time is: 98.5001163482666 seconds\n",
      "Model: repeat_dict index encoding_One-Class SVM, accuracy score: 0.13615023474178403, testing time is: 2.987658977508545 seconds\n",
      "Model: repeat_dict index encoding_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.032010793685913086 seconds\n",
      "Model: repeat_dict index encoding_Isolation Forest, accuracy score: 0.8286384976525821, testing time is: 4.451995849609375 seconds\n",
      "Model: spoof_dict index encoding-pca_Robust covariance, accuracy score: 0.9637305699481865, testing time is: 0.0030014514923095703 seconds\n",
      "Model: spoof_dict index encoding-pca_One-Class SVM, accuracy score: 0.0, testing time is: 0.02800607681274414 seconds\n",
      "Model: spoof_dict index encoding-pca_SGD One-Class SVM, accuracy score: 0.9559585492227979, testing time is: 0.0010004043579101562 seconds\n",
      "Model: spoof_dict index encoding-pca_Isolation Forest, accuracy score: 0.966321243523316, testing time is: 0.11402606964111328 seconds\n",
      "Model: spoof_dict index encoding_Robust covariance, accuracy score: 0.6528497409326425, testing time is: 94.00809097290039 seconds\n",
      "Model: spoof_dict index encoding_One-Class SVM, accuracy score: 0.09326424870466321, testing time is: 1.8824219703674316 seconds\n",
      "Model: spoof_dict index encoding_SGD One-Class SVM, accuracy score: 1.0, testing time is: 0.024007320404052734 seconds\n",
      "Model: spoof_dict index encoding_Isolation Forest, accuracy score: 0.6683937823834197, testing time is: 3.6558194160461426 seconds\n"
     ]
    }
   ],
   "source": [
    "resultsdict = dict()\n",
    "predsdict = dict()\n",
    "classifiersdict = dict()\n",
    "pcas = dict()\n",
    "for feature in features:\n",
    "    #train stage\n",
    "    clfs, results, preds, pca = train_models(feature, normal)\n",
    "    \n",
    "    resultsdict[feature+'_validation'] = results\n",
    "    predsdict[feature+'_validation'] = preds\n",
    "    classifiersdict[feature] = clfs\n",
    "    pcas[feature] = pca\n",
    "    # testing stage\n",
    "    for malware in malwares:\n",
    "        results, preds = test_models(malware, feature, clfs, pca)\n",
    "        resultsdict[malware +'_' + feature] = results\n",
    "        predsdict[malware +'_' + feature] = preds\n",
    "        \n",
    "loc=open(resultsPath+'classifiers.pk','wb')\n",
    "pickle.dump(classifiersdict,loc)\n",
    "loc=open(resultsPath+'results.pk','wb')\n",
    "pickle.dump(resultsdict,loc)\n",
    "loc=open(resultsPath+'preds.pk','wb')\n",
    "pickle.dump(predsdict,loc)   \n",
    "loc=open(resultsPath+'pcas.pk','wb')\n",
    "pickle.dump(pca,loc)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = []\n",
    "for rs in resultsdict:\n",
    "    for r in resultsdict[rs]:\n",
    "        for s in r:\n",
    "            rd.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = pd.DataFrame(rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = [i.split('_') for i in rd['Model']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = pd.DataFrame(md)\n",
    "md.columns  = ['Dataset','Features','Model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Robust covariance\n",
       "1          One-Class SVM\n",
       "2      SGD One-Class SVM\n",
       "3       Isolation Forest\n",
       "4      Robust covariance\n",
       "             ...        \n",
       "319     Isolation Forest\n",
       "320    Robust covariance\n",
       "321        One-Class SVM\n",
       "322    SGD One-Class SVM\n",
       "323     Isolation Forest\n",
       "Name: Model, Length: 324, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md['Model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrd=pd.DataFrame([md['Dataset'],md['Features'],md['Model'], rd['Accuracy']]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>valid</td>\n",
       "      <td>system calls frequency-pca</td>\n",
       "      <td>Robust covariance</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>valid</td>\n",
       "      <td>system calls frequency-pca</td>\n",
       "      <td>One-Class SVM</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valid</td>\n",
       "      <td>system calls frequency-pca</td>\n",
       "      <td>SGD One-Class SVM</td>\n",
       "      <td>0.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>valid</td>\n",
       "      <td>system calls frequency-pca</td>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>0.78125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>valid</td>\n",
       "      <td>system calls frequency</td>\n",
       "      <td>Robust covariance</td>\n",
       "      <td>0.867188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>spoof</td>\n",
       "      <td>dict index encoding-pca</td>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>0.966321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>spoof</td>\n",
       "      <td>dict index encoding</td>\n",
       "      <td>Robust covariance</td>\n",
       "      <td>0.65285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>spoof</td>\n",
       "      <td>dict index encoding</td>\n",
       "      <td>One-Class SVM</td>\n",
       "      <td>0.093264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>spoof</td>\n",
       "      <td>dict index encoding</td>\n",
       "      <td>SGD One-Class SVM</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>spoof</td>\n",
       "      <td>dict index encoding</td>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>0.668394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset                    Features              Model  Accuracy\n",
       "0     valid  system calls frequency-pca  Robust covariance  0.828125\n",
       "1     valid  system calls frequency-pca      One-Class SVM       0.0\n",
       "2     valid  system calls frequency-pca  SGD One-Class SVM  0.359375\n",
       "3     valid  system calls frequency-pca   Isolation Forest   0.78125\n",
       "4     valid      system calls frequency  Robust covariance  0.867188\n",
       "..      ...                         ...                ...       ...\n",
       "319   spoof     dict index encoding-pca   Isolation Forest  0.966321\n",
       "320   spoof         dict index encoding  Robust covariance   0.65285\n",
       "321   spoof         dict index encoding      One-Class SVM  0.093264\n",
       "322   spoof         dict index encoding  SGD One-Class SVM       1.0\n",
       "323   spoof         dict index encoding   Isolation Forest  0.668394\n",
       "\n",
       "[324 rows x 4 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrd.to_csv(resultsPath+'results.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
