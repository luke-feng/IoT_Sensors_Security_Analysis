{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import OneClassSVM\n",
    "import time\n",
    "import copy\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "import os,sys\n",
    "import tqdm\n",
    "import pickle\n",
    "import time\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = 'd:/mt_data/1212_withrw/encoded/t1/'\n",
    "dictPath = 'd:/mt_data/1126_withrw/encoded/t1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [ 'pi3', 'pi4_2G', 'pi4_4G']\n",
    "tws = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ \n",
    "    'system calls frequency_1gram', \n",
    "    'system calls tfidf_1gram',\n",
    "    'system calls frequency_2gram', \n",
    "    'system calls tfidf_2gram',\n",
    "    'system calls frequency_3gram',\n",
    "    'system calls tfidf_3gram', \n",
    "    'system calls frequency_4gram', \n",
    "    'system calls tfidf_4gram',\n",
    "    'system calls frequency_5gram',\n",
    "    'system calls tfidf_5gram'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "onepath = os.getcwd()+'/' +'onedata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_name = onepath+'encoded_bow{}_{}_{}.csv'.format(d, tws, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_df = pd.read_csv(tsv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.1549480754759887, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "Name: system calls tfidf_5gram, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_df['system calls tfidf_5gram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in devices:\n",
    "    for f in features:\n",
    "        tsv_name = dataPath+'encoded_bow{}_{}_{}.csv'.format(d, tws, f)\n",
    "        tsv_df = pd.read_csv(tsv_name, sep='\\t')\n",
    "        tsv_df[0:1].to_csv(onepath+'encoded_bow{}_{}_{}.csv'.format(d, tws, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_feature_tsv(device, tw, ftname):\n",
    "    tsv_name = dataPath+'encoded_bow{}_{}_{}.csv'.format(device, tw, ftname)\n",
    "    tsv_df = pd.read_csv(tsv_name, sep='\\t')\n",
    "    feature = [ast.literal_eval(i) for i in tsv_df[ftname]]\n",
    "    tsv_df[ftname] = feature\n",
    "    normal = tsv_df[tsv_df.maltype=='normal'][ftname].tolist() \n",
    "    return normal, tsv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_feature_tsv(device, tw, ftname):\n",
    "    tsv_name = dataPath+'encoded_bow{}_{}_{}.csv'.format(device, tw, ftname)\n",
    "    tsv_df = pd.read_csv(tsv_name, sep='\\t')\n",
    "    feature = [ast.literal_eval(i) for i in tsv_df[ftname]]\n",
    "    tsv_df[ftname] = feature\n",
    "    normal = tsv_df[tsv_df.maltype=='normal'][ftname].tolist() \n",
    "    X_train, X_val = train_test_split(normal, test_size=.3, shuffle=False) \n",
    "    return X_train, X_val, tsv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(device, tw, ftname):\n",
    "    X_train, X_val, tsv_df = read_feature_tsv(device, tw, ftname)\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    data = scaler.transform(tsv_df[ftname].tolist())\n",
    "    normaled_df = pd.DataFrame([tsv_df['ids'].tolist(), tsv_df['maltype'].tolist(), data.tolist()]).transpose()\n",
    "    scaledName = dataPath+'{}_{}_{}-scaled.pk'.format(device, tw, ftname)\n",
    "    loc = open(scaledName,'wb')\n",
    "    pickle.dump(scaler, loc)\n",
    "    loc.close()\n",
    "    ftname = ftname+'-scaled'\n",
    "    normaled_df.columns = ['ids', 'maltype', ftname]\n",
    "    dfName = dataPath+'encoded_bow{}_{}_{}.csv'.format(device, tw, ftname)\n",
    "    normaled_df.to_csv(dfName, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(device, tw, ftname):\n",
    "    X_train, tsv_df = read_feature_tsv(device, tw, ftname)\n",
    "    scaledName = dictPath+'{}_{}_{}-pcas.pk'.format(device, tw, ftname)\n",
    "    loc = open(scaledName,'rb')\n",
    "    scaler = pickle.load(loc)\n",
    "    data = scaler.transform(X_train)\n",
    "    normaled_df = pd.DataFrame([tsv_df['ids'].tolist(), tsv_df['maltype'].tolist(), data.tolist()]).transpose()\n",
    "    ftname = ftname+'-pcas'\n",
    "    normaled_df.columns = ['ids', 'maltype', ftname]\n",
    "    dfName = dataPath+'encoded_bow{}_{}_{}.csv'.format(device, tw, ftname)\n",
    "    normaled_df.to_csv(dfName, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ \n",
    "    'system calls frequency_2gram', \n",
    "    'system calls tfidf_2gram',\n",
    "    'system calls frequency_3gram',\n",
    "    'system calls tfidf_3gram', \n",
    "    'system calls frequency_4gram', \n",
    "    'system calls tfidf_4gram',\n",
    "    'system calls frequency_5gram',\n",
    "    'system calls tfidf_5gram'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for device in devices:\n",
    "    for ftname in features:\n",
    "        normal(device, 60, ftname)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
