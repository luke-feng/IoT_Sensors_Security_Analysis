{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import OneClassSVM\n",
    "import time\n",
    "import copy\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "import os,sys\n",
    "import tqdm\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import ast\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import torch as T\n",
    "# import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Autoencoder_DNN(T.nn.Module):  # input_len-32-8-32-input_len\n",
    "#   def __init__(self, input_len):\n",
    "#     super(Autoencoder_DNN, self).__init__()\n",
    "#     self.fc1 = T.nn.Linear(input_len, 64)\n",
    "#     self.fc2 = T.nn.Linear(64, 16)\n",
    "#     self.fc3 = T.nn.Linear(16, 8)\n",
    "#     self.fc4 = T.nn.Linear(8, 16)\n",
    "#     self.fc5 = T.nn.Linear(16, 64)\n",
    "#     self.fc6 = T.nn.Linear(64, input_len)\n",
    "\n",
    "#   def encode(self, x):  # input_len-32-8\n",
    "#     z = T.relu(self.fc1(x))\n",
    "#     z = T.relu(self.fc2(z)) \n",
    "#     z = T.relu(self.fc3(z)) \n",
    "#     return z  \n",
    "\n",
    "#   def decode(self, x):  # 8-32-input_len\n",
    "#     z = T.relu(self.fc4(x))\n",
    "#     z = T.relu(self.fc5(z)) \n",
    "#     z = T.relu(self.fc6(z)) \n",
    "#     return z\n",
    "    \n",
    "#   def forward(self, x):  # 65-32-8-32-65\n",
    "#     z = self.encode(x) \n",
    "#     z = self.decode(z) \n",
    "#     return z  # in [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curPath = os.curdir\n",
    "# loc = open(curPath+'/' + 'fl.pk','rb')\n",
    "# net = pickle.load( loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "curPath = os.curdir\n",
    "loc = open(curPath+'/' + 'fl.pk','rb')\n",
    "model = pickle.load( loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_threshold(net, X_train):\n",
    "#     net = net.eval()\n",
    "#     loss_func = T.nn.MSELoss()\n",
    "#     with T.no_grad():\n",
    "#         x_t = T.Tensor(X_train)\n",
    "#         y_t = net(x_t)\n",
    "#         y_pred = np.array([loss_func(y_t[i],x_t[i]).item() for i in range(0,len(x_t))])\n",
    "#     down_threshold = np.percentile(y_pred, 2.5)\n",
    "#     up_threshold = np.percentile(y_pred, 97.5)\n",
    "#     return down_threshold, up_threshold\n",
    "\n",
    "# def test(net, X, down_threshold, up_threshold):\n",
    "#     net = net.eval()  \n",
    "#     loss_func = T.nn.MSELoss()\n",
    "#     y_pred = []\n",
    "#     loss = 0\n",
    "#     with T.no_grad():\n",
    "#         for i in range(0,len(X)):\n",
    "#             x = T.Tensor(X[i])\n",
    "#             y_t = net(x)\n",
    "#             t = loss_func(y_t,x).item()\n",
    "#             loss += t\n",
    "#             if t > down_threshold and t < up_threshold:\n",
    "#                 y_pred.append(1)\n",
    "#             else:\n",
    "#                 y_pred.append(-1)\n",
    "#     loss = loss/len(X)\n",
    "#     return y_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature ='system calls frequency_1gram-scaled'\n",
    "# data = utils.load_all_data(feature)\n",
    "# (X_train, y_train), (X_test, y_test) = utils.load_data_node1(data, feature)\n",
    "# X_train = T.FloatTensor(X_train)\n",
    "# down_threshold, up_threshold = find_threshold(net, X_train)\n",
    "# pred_val, loss = test(net, X_train, down_threshold, up_threshold)\n",
    "# pred_test, loss = test(net, X_test, down_threshold, up_threshold)\n",
    "# val_acc = metrics.accuracy_score(pred_val, y_train)\n",
    "# test_acc = metrics.accuracy_score(pred_test, y_test)\n",
    "# print(f\"accuracy {val_acc, test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature ='system calls frequency_1gram-scaled'\n",
    "# data = utils.load_all_data(feature)\n",
    "# (X_train, y_train), (X_test, y_test) = utils.load_data_node2(data, feature)\n",
    "# X_train = T.FloatTensor(X_train)\n",
    "# down_threshold, up_threshold = find_threshold(net, X_train)\n",
    "# pred_val, loss = test(net, X_train, down_threshold, up_threshold)\n",
    "# pred_test, loss = test(net, X_test, down_threshold, up_threshold)\n",
    "# val_acc = metrics.accuracy_score(pred_val, y_train)\n",
    "# test_acc = metrics.accuracy_score(pred_test, y_test)\n",
    "# print(f\"accuracy {val_acc, test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature ='system calls frequency_1gram-scaled'\n",
    "# data = utils.load_all_data(feature)\n",
    "# (X_train, y_train), (X_test, y_test) = utils.load_data_node3(data, feature)\n",
    "# X_train = T.FloatTensor(X_train)\n",
    "# down_threshold, up_threshold = find_threshold(net, X_train)\n",
    "# pred_val, loss = test(net, X_train, down_threshold, up_threshold)\n",
    "# pred_test, loss = test(net, X_test, down_threshold, up_threshold)\n",
    "# val_acc = metrics.accuracy_score(pred_val, y_train)\n",
    "# test_acc = metrics.accuracy_score(pred_test, y_test)\n",
    "# print(f\"accuracy {val_acc, test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature ='system calls frequency_1gram-scaled'\n",
    "# data = utils.load_all_data(feature)\n",
    "# (X_train, y_train), (X_test, y_test) = utils.load_data_node4(data, feature)\n",
    "# X_train = T.FloatTensor(X_train)\n",
    "# down_threshold, up_threshold = find_threshold(net, X_train)\n",
    "# pred_val, loss = test(net, X_train, down_threshold, up_threshold)\n",
    "# pred_test, loss = test(net, X_test, down_threshold, up_threshold)\n",
    "# val_acc = metrics.accuracy_score(pred_val, y_train)\n",
    "# test_acc = metrics.accuracy_score(pred_test, y_test)\n",
    "# print(f\"accuracy {val_acc, test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature ='system calls frequency_1gram-scaled'\n",
    "# data = utils.load_all_data(feature)\n",
    "# (X_train, y_train), (X_test, y_test) = utils.load_data_node5(data, feature)\n",
    "# X_train = T.FloatTensor(X_train)\n",
    "# down_threshold, up_threshold = find_threshold(net, X_train)\n",
    "# pred_val, loss = test(net, X_train, down_threshold, up_threshold)\n",
    "# pred_test, loss = test(net, X_test, down_threshold, up_threshold)\n",
    "# val_acc = metrics.accuracy_score(pred_val, y_train)\n",
    "# test_acc = metrics.accuracy_score(pred_test, y_test)\n",
    "# print(f\"accuracy {val_acc, test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature ='system calls frequency_1gram-scaled'\n",
    "# data = utils.load_all_data(feature)\n",
    "# (X_train, y_train), (X_test, y_test) = utils.load_data_node6(data, feature)\n",
    "# X_train = T.FloatTensor(X_train)\n",
    "# down_threshold, up_threshold = find_threshold(net, X_train)\n",
    "# pred_val, loss = test(net, X_train, down_threshold, up_threshold)\n",
    "# pred_test, loss = test(net, X_test, down_threshold, up_threshold)\n",
    "# val_acc = metrics.accuracy_score(pred_val, y_train)\n",
    "# test_acc = metrics.accuracy_score(pred_test, y_test)\n",
    "# print(f\"accuracy {val_acc, test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (0.8111111111111111, 0.9899305555555555)\n"
     ]
    }
   ],
   "source": [
    "feature ='system calls frequency_1gram-scaled'\n",
    "data = utils.load_all_data(feature)\n",
    "(X_train, y_train), (X_test, y_test) = utils.load_data_node1(data, feature)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.3, shuffle=False)\n",
    "val_acc = metrics.accuracy_score(model.predict(X_train), y_train)\n",
    "test_acc = metrics.accuracy_score(model.predict(X_test), y_test)\n",
    "print(f\"accuracy {val_acc, test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (0.7333333333333333, 0.9885416666666667)\n"
     ]
    }
   ],
   "source": [
    "feature ='system calls frequency_1gram-scaled'\n",
    "data = utils.load_all_data(feature)\n",
    "(X_train, y_train), (X_test, y_test) = utils.load_data_node2(data, feature)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.3, shuffle=False)\n",
    "val_acc = metrics.accuracy_score(model.predict(X_train), y_train)\n",
    "test_acc = metrics.accuracy_score(model.predict(X_test), y_test)\n",
    "print(f\"accuracy {val_acc, test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (0.7111111111111111, 0.9979166666666667)\n"
     ]
    }
   ],
   "source": [
    "feature ='system calls frequency_1gram-scaled'\n",
    "data = utils.load_all_data(feature)\n",
    "(X_train, y_train), (X_test, y_test) = utils.load_data_node3(data, feature)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.3, shuffle=False)\n",
    "val_acc = metrics.accuracy_score(model.predict(X_train), y_train)\n",
    "test_acc = metrics.accuracy_score(model.predict(X_test), y_test)\n",
    "print(f\"accuracy {val_acc, test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (0.5666666666666667, 0.9989583333333333)\n"
     ]
    }
   ],
   "source": [
    "feature ='system calls frequency_1gram-scaled'\n",
    "data = utils.load_all_data(feature)\n",
    "(X_train, y_train), (X_test, y_test) = utils.load_data_node4(data, feature)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.3, shuffle=False)\n",
    "val_acc = metrics.accuracy_score(model.predict(X_train), y_train)\n",
    "test_acc = metrics.accuracy_score(model.predict(X_test), y_test)\n",
    "print(f\"accuracy {val_acc, test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (0.8111111111111111, 0.9986111111111111)\n"
     ]
    }
   ],
   "source": [
    "feature ='system calls frequency_1gram-scaled'\n",
    "data = utils.load_all_data(feature)\n",
    "(X_train, y_train), (X_test, y_test) = utils.load_data_node5(data, feature)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.3, shuffle=False)\n",
    "val_acc = metrics.accuracy_score(model.predict(X_train), y_train)\n",
    "test_acc = metrics.accuracy_score(model.predict(X_test), y_test)\n",
    "print(f\"accuracy {val_acc, test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (0.8527777777777777, 0.9986111111111111)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = utils.load_data_node6(data, feature)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.3, shuffle=False)\n",
    "val_acc = metrics.accuracy_score(model.predict(X_train), y_train)\n",
    "test_acc = metrics.accuracy_score(model.predict(X_test), y_test)\n",
    "print(f\"accuracy {val_acc, test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
