{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import OneClassSVM\n",
    "import time\n",
    "import copy\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "import os,sys\n",
    "import tqdm\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import ast\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import torch as T\n",
    "# import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = 'D:/mt_data/data/'\n",
    "feature ='system calls tfidf_1gram'\n",
    "filename = 'encoded_bow_{}.csv'.format(feature)\n",
    "t1 = dataPath+filename\n",
    "t1df = pd.read_csv(t1, sep='\\t')\n",
    "t1data = [ast.literal_eval(i) for i in t1df['data']]\n",
    "data = pd.DataFrame([t1df['device'].tolist(), t1df['label'].tolist(), t1df['malware'].tolist(), t1data]).transpose()\n",
    "data.columns = ['device', 'label','malware', 'data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindevice = 'pi4_4G_t1'\n",
    "test1device = 'pi3_t1'\n",
    "test2device = 'pi4_2G_t1'\n",
    "td = 'pi4_4G'\n",
    "test3device = 'pi3_t2'\n",
    "test4device = 'pi4_2G_t2'\n",
    "test5device = 'pi4_4G_t2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledPath =  'd:/mt_data/1126_withrw/encoded/t1/' + '{}_{}_{}-scaled.pk'.format(td, 60, feature)\n",
    "loc = open(scaledPath, 'rb')\n",
    "scaled = pickle.load(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[(data['device']==traindevice)&(data.malware=='normal')]['data'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled.transform(X).tolist()\n",
    "y = [1 for i in range(0, len(X))]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle=False, test_size=.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data[(data['device']==test1device)&(data.label==-1)]['data'].tolist()\n",
    "X_test = scaled.transform(X_test).tolist()\n",
    "y_test =  [-1 for i in range(0, len(X_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_normal = data[(data['device']==test1device)&(data.malware=='normal')]['data'].tolist()\n",
    "test1_normal = scaled.transform(test1_normal).tolist()\n",
    "\n",
    "test1_attack = data[(data['device']==test1device)&(data.label==-1)]['data'].tolist()\n",
    "test1_attack = scaled.transform(test1_attack).tolist()\n",
    "y1_normal =  [1 for i in range(0, len(test1_normal))]\n",
    "y1_attack =  [-1 for i in range(0, len(test1_attack))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_normal = data[(data['device']==test2device)&(data.malware=='normal')]['data'].tolist()\n",
    "test2_normal = scaled.transform(test2_normal).tolist()\n",
    "test2_attack = data[(data['device']==test2device)&(data.label==-1)]['data'].tolist()\n",
    "test2_attack = scaled.transform(test2_attack).tolist()\n",
    "y2_normal =  [1 for i in range(0, len(test2_normal))]\n",
    "y2_attack =  [-1 for i in range(0, len(test2_attack))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3_normal = data[(data['device']==test3device)&(data.malware=='normal')]['data'].tolist()\n",
    "test3_normal = scaled.transform(test3_normal).tolist()\n",
    "y3_normal =  [1 for i in range(0, len(test3_normal))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "test4_normal = data[(data['device']==test4device)&(data.malware=='normal')]['data'].tolist()\n",
    "test4_normal = scaled.transform(test4_normal).tolist()\n",
    "y4_normal =  [1 for i in range(0, len(test4_normal))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "test5_normal = data[(data['device']==test5device)&(data.malware=='normal')]['data'].tolist()\n",
    "test5_normal = scaled.transform(test5_normal).tolist()\n",
    "y5_normal =  [1 for i in range(0, len(test5_normal))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "for da in [X_train, X_val, X_test, test1_normal, test1_attack, test2_normal, test2_attack, test3_normal, test4_normal, test5_normal]:\n",
    "    for d in da:\n",
    "        d.pop(6)\n",
    "        d.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OneClassSVM(cache_size=200, gamma='scale', kernel='rbf',nu=0.01,  shrinking=True,  tol=1e-6,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_DNN(T.nn.Module):  # input_len-32-8-32-input_len\n",
    "  def __init__(self, input_len):\n",
    "    super(Autoencoder_DNN, self).__init__()\n",
    "    self.fc1 = T.nn.Linear(input_len, 64)\n",
    "    self.fc2 = T.nn.Linear(64, 16)\n",
    "    self.fc3 = T.nn.Linear(16, 8)\n",
    "    self.fc4 = T.nn.Linear(8, 16)\n",
    "    self.fc5 = T.nn.Linear(16, 64)\n",
    "    self.fc6 = T.nn.Linear(64, input_len)\n",
    "\n",
    "  def encode(self, x):  # input_len-32-8\n",
    "    z = T.relu(self.fc1(x))\n",
    "    z = T.relu(self.fc2(z)) \n",
    "    z = T.relu(self.fc3(z)) \n",
    "    return z  \n",
    "\n",
    "  def decode(self, x):  # 8-32-input_len\n",
    "    z = T.relu(self.fc4(x))\n",
    "    z = T.relu(self.fc5(z)) \n",
    "    z = T.relu(self.fc6(z)) \n",
    "    return z\n",
    "    \n",
    "  def forward(self, x):  # 65-32-8-32-65\n",
    "    z = self.encode(x) \n",
    "    z = self.decode(z) \n",
    "    return z  # in [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, input_len):\n",
    "    net = Autoencoder_DNN(input_len)\n",
    "    net = net.train() \n",
    "    loss_func = T.nn.MSELoss()\n",
    "    optimizer = T.optim.Adam(net.parameters(), lr=0.01)\n",
    "    max_epochs = 50\n",
    "    # print(\"Starting training\")\n",
    "    last_val_loss = float(\"inf\")\n",
    "    patience = 0\n",
    "    last_loss = 0\n",
    "    for epoch in range(0, max_epochs):\n",
    "        loss = 0\n",
    "        # if epoch > 0 and epoch % (max_epochs/10) == 0:\n",
    "        #     print(\"epoch = %6d\" % epoch, end=\"\")\n",
    "        #     print(\" prev total loss = %7.4f, perv total val-loss = %7.4f\" %( last_loss,val_loss))\n",
    "        for curr_bat in train_loader:\n",
    "            X = T.Tensor(curr_bat)\n",
    "            optimizer.zero_grad()\n",
    "            oupt = net(X)\n",
    "            loss_obj = loss_func(oupt, X)  # note X not Y\n",
    "            loss += loss_obj.item()\n",
    "            loss_obj.backward()\n",
    "            optimizer.step()\n",
    "        last_loss = loss\n",
    "        val_loss = 0\n",
    "        with T.no_grad():\n",
    "            for curr_bat in val_loader:\n",
    "                X = T.Tensor(curr_bat)\n",
    "                oupt = net(X)\n",
    "                val_loss_obj = loss_func(oupt, X)  # note X not Y\n",
    "                val_loss += val_loss_obj.item()\n",
    "            # print(loss, val_loss)\n",
    "            if val_loss < last_val_loss:\n",
    "                last_val_loss = val_loss\n",
    "                patience = 0\n",
    "            else:\n",
    "                patience += 1\n",
    "        if patience >= 10:\n",
    "            break               \n",
    "    # print(\"Training stop at epochï¼š %d\" %epoch)\n",
    "    return net\n",
    "\n",
    "def find_threshold(net, X_train):\n",
    "    net = net.eval()\n",
    "    loss_func = T.nn.MSELoss()\n",
    "    with T.no_grad():\n",
    "        x_t = T.Tensor(X_train)\n",
    "        y_t = net(x_t)\n",
    "        y_pred = np.array([loss_func(y_t[i],x_t[i]).item() for i in range(0,len(x_t))])\n",
    "    down_threshold = np.percentile(y_pred, 2.5)\n",
    "    up_threshold = np.percentile(y_pred, 97.5)\n",
    "    return down_threshold, up_threshold\n",
    "\n",
    "def test(net, X, down_threshold, up_threshold):\n",
    "    net = net.eval()  \n",
    "    loss_func = T.nn.MSELoss()\n",
    "    y_pred = []\n",
    "    with T.no_grad():\n",
    "        for i in range(0,len(X)):\n",
    "            x = T.Tensor(X[i])\n",
    "            y_t = net(x)\n",
    "            t = loss_func(y_t,x).item()\n",
    "            if t > down_threshold and t < up_threshold:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(-1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = T.FloatTensor(X_train)\n",
    "# X_val = T.FloatTensor(X_val)\n",
    "# train_loader = T.utils.data.DataLoader(X_train, batch_size=256, shuffle=False, drop_last=False, pin_memory=True, num_workers=2)\n",
    "# val_loader = T.utils.data.DataLoader(X_val, batch_size=256, shuffle=False, drop_last=False, num_workers=2)\n",
    "# input_len = len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = train(train_loader,val_loader, input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down_threshold, up_threshold = find_threshold(net, X_train)\n",
    "# y_pred = test(net, X_val, down_threshold, up_threshold)\n",
    "# val_score = metrics.accuracy_score(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.accuracy_score(test(net, X_val, down_threshold, up_threshold), y_val), metrics.accuracy_score(test(net, X_test, down_threshold, up_threshold), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.accuracy_score(test(net, test1_normal, down_threshold, up_threshold), y1_normal), metrics.accuracy_score(test(net, test1_attack, down_threshold, up_threshold), y1_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.accuracy_score(test(net, test2_normal, down_threshold, up_threshold), y2_normal), metrics.accuracy_score(test(net, test2_attack, down_threshold, up_threshold), y2_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.accuracy_score(test(net, test3_normal, down_threshold, up_threshold), y3_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.accuracy_score(test(net, test4_normal, down_threshold, up_threshold), y4_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.accuracy_score(test(net, test5_normal, down_threshold, up_threshold), y5_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =make_pipeline(\n",
    "#             Nystroem(gamma=0.6, random_state=42, n_components=150),\n",
    "#             SGDOneClassSVM(\n",
    "#                 nu=0.05,\n",
    "#                 shuffle=True,\n",
    "#                 fit_intercept=True,\n",
    "#                 random_state=42,\n",
    "#                 tol=1e-6,\n",
    "#             ),\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(nu=0.01, tol=1e-06)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8703703703703703, 1.0)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(model.predict(X_val), y_val), metrics.accuracy_score(model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(model.predict(test1_normal), y1_normal), metrics.accuracy_score(model.predict(test1_attack), y1_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8916666666666667, 0.9965277777777778)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(model.predict(test2_normal), y2_normal), metrics.accuracy_score(model.predict(test2_attack), y2_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(model.predict(test3_normal), y3_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6527777777777778"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(model.predict(test4_normal), y4_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8944444444444445"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(model.predict(test5_normal), y5_normal)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
